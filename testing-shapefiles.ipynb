{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the relevant modules\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "\n",
    "# Import third party modules\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dictionaries_em as dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"/home/users/benhutch/energy-met-corr-functions\")\n",
    "\n",
    "# Import the functions\n",
    "import functions_em as funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'functions_em' from '/home/users/benhutch/energy-met-corr-functions/functions_em.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "\n",
    "importlib.reload(funcs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate onshore wind correlations ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solar correlations ###\n",
    "\n",
    "Looking at correlations between climate indices (solar irradiance, NAO, delta P) and countrywide solar power generation from the CLEARHEADS data.\n",
    "\n",
    "The data we want is in:\n",
    "\n",
    "* *NUTS_0_sp_historical.nc* - Hourly area-averaged solar power capacity factors at NUTS0 level across Europe from 1950 to 2020.\n",
    "* *NUTS_0_sp_historical_loc_weighted.nc* - Hourly solar power capacity factors at NUTS0 level across Europe, from 01/01/1950 - 31/12/2020. Data is weighted by the location of known solar panels from Dunnett et al., (2020) and Stowell et al., (2020) for the UK.\n",
    "    * This dataset appears to be buggy, use the former."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUTS_keys for UREAD data:  ['AT' 'AL' 'BY' 'BE' 'BA' 'BG' 'HR' 'CZ' 'DK' 'EE' 'FI' 'FR' 'DE' 'GR'\n",
      " 'HU' 'IE' 'IT' 'XK' 'LV' 'LT' 'LU' 'MK' 'MD' 'ME' 'NL' 'NO' 'PL' 'PT'\n",
      " 'RO' 'RS' 'SK' 'SI' 'ES' 'SE' 'CH' 'TR' 'UA' 'UK']\n",
      "Trend levels for UREAD data:  [1950. 1980. 2010. 2020.    0.]\n",
      "Using mean sea level pressure to calculate the NAO index.\n",
      "NAO df head:              NAO anomaly (Pa)\n",
      "time                        \n",
      "1964-12-31       -459.574041\n",
      "1965-12-31       -690.520941\n",
      "1966-12-31       -668.601591\n",
      "1967-12-31       -603.603464\n",
      "1968-12-31       -487.695747\n",
      "df head:                                           AT        AL        BY        BE  \\\n",
      "time_in_hours_from_first_jan_1950                                           \n",
      "1954-12-31                        -0.282374  6.197794 -2.404402  4.137139   \n",
      "1955-12-31                        -0.228388  6.116533 -2.150352  4.272940   \n",
      "1956-12-31                        -0.187530  6.158265 -2.298663  4.382628   \n",
      "1957-12-31                         0.056891  6.314317 -1.830545  4.734469   \n",
      "1958-12-31                         0.060292  6.492480 -1.501078  4.712124   \n",
      "\n",
      "                                         BA        BG        HR        CZ  \\\n",
      "time_in_hours_from_first_jan_1950                                           \n",
      "1954-12-31                         3.148766  3.752242  5.699981  0.910602   \n",
      "1955-12-31                         3.122514  3.595280  5.697433  1.011465   \n",
      "1956-12-31                         3.237519  3.613975  5.796910  0.985699   \n",
      "1957-12-31                         3.567698  3.839550  6.119801  1.274680   \n",
      "1958-12-31                         3.757451  4.296503  6.294649  1.359746   \n",
      "\n",
      "                                         DK        EE  ...        RO  \\\n",
      "time_in_hours_from_first_jan_1950                      ...             \n",
      "1954-12-31                         2.955480 -2.247489  ...  1.603900   \n",
      "1955-12-31                         3.144135 -1.949176  ...  1.482399   \n",
      "1956-12-31                         3.023829 -2.208487  ...  1.487941   \n",
      "1957-12-31                         3.216735 -1.799230  ...  1.802905   \n",
      "1958-12-31                         3.205232 -1.659751  ...  2.227419   \n",
      "\n",
      "                                         RS        SK        SI        ES  \\\n",
      "time_in_hours_from_first_jan_1950                                           \n",
      "1954-12-31                         3.435496  0.849508  2.444436  8.653419   \n",
      "1955-12-31                         3.271197  0.870788  2.500648  8.737586   \n",
      "1956-12-31                         3.259991  0.949820  2.605166  8.823612   \n",
      "1957-12-31                         3.522339  1.250694  2.943082  8.932594   \n",
      "1958-12-31                         3.865943  1.466470  3.077182  9.002675   \n",
      "\n",
      "                                         SE        CH        TR        UA  \\\n",
      "time_in_hours_from_first_jan_1950                                           \n",
      "1954-12-31                        -4.089416 -1.501231  5.812725 -0.219389   \n",
      "1955-12-31                        -3.825475 -1.404861  5.547853 -0.153867   \n",
      "1956-12-31                        -3.951885 -1.317075  5.602999 -0.251544   \n",
      "1957-12-31                        -3.779464 -1.032249  5.613472  0.087704   \n",
      "1958-12-31                        -3.985993 -1.080707  5.909311  0.653264   \n",
      "\n",
      "                                         UK  \n",
      "time_in_hours_from_first_jan_1950            \n",
      "1954-12-31                         5.175983  \n",
      "1955-12-31                         5.342973  \n",
      "1956-12-31                         5.388282  \n",
      "1957-12-31                         5.531901  \n",
      "1958-12-31                         5.389706  \n",
      "\n",
      "[5 rows x 38 columns]\n"
     ]
    }
   ],
   "source": [
    "# Ste up the model config\n",
    "# Set up the model config\n",
    "# model_config = {\n",
    "#     \"variable\": \"rsds\",\n",
    "#     \"season\": \"ONDJFM\",\n",
    "#     \"region\": \"global\",\n",
    "#     \"start_year\": 1964,\n",
    "#     \"end_year\": 2014,\n",
    "#     \"forecast_range\": \"2-9\",\n",
    "#     \"lag\": 4,\n",
    "#     \"method\": \"alternate_lag\",\n",
    "# }\n",
    "\n",
    "# rsds_global_ONDJFM_2-9_1961_2014_4_West Mediterranean_nao_matched.csv\n",
    "# model_config = {\n",
    "#     \"variable\": \"psl\",\n",
    "#     \"season\": \"ONDJFM\",\n",
    "#     \"region\": \"global\",\n",
    "#     \"nao\": \"nao_default\",\n",
    "#     \"start_year\": 1961,\n",
    "#     \"end_year\": 2014,\n",
    "#     \"forecast_range\": \"2-9\",\n",
    "#     \"lag\": 4,\n",
    "#     \"method\": \"alternate_lag\",\n",
    "# }\n",
    "\n",
    "# file=\"NUTS_0_t2m_detrended_timeseries_historical_pop_weighted.nc\",\n",
    "# shp_file=\"NUTS_RG_10M_2021_4326.shp\",\n",
    "# shp_file_dir=\"/home/users/benhutch/shapefiles/NUTS/\",\n",
    "# label=\"Pop. weighted temp (K)\",\n",
    "# trend_level=2020.0,\n",
    "\n",
    "# model config for 10m wind speeds\n",
    "model_config = {\n",
    "    \"variable\": \"psl\",\n",
    "    \"season\": \"ONDJFM\",\n",
    "    \"region\": \"global\",\n",
    "    \"nao\": \"thornton_2019\",\n",
    "    \"start_year\": 1961,\n",
    "    \"end_year\": 2014,\n",
    "    \"forecast_range\": \"2-9\",\n",
    "    \"lag\": 4,\n",
    "    \"method\": \"alt_lag\",\n",
    "}\n",
    "\n",
    "# ~/shapefiles/NUTS/NUTS_RG_10M_2021_4326.shp\n",
    "\n",
    "# NUTS_0_wp_ons_sim_1_historical_loc_weighted.n\n",
    "# weighted by location of known and proposed future wind farms\n",
    "\n",
    "# Call the function\n",
    "# TODO: onshore wind correlations\n",
    "dfs = funcs.correlate_nao_uread(\n",
    "    filename=\"NUTS_0_t2m_detrended_timeseries_historical.nc\",\n",
    "    trend_level=0.0,\n",
    ")\n",
    "\n",
    "# use_model_data=True,\n",
    "# model_config=model_config,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df, corr_df = dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>AL</th>\n",
       "      <th>BY</th>\n",
       "      <th>BE</th>\n",
       "      <th>BA</th>\n",
       "      <th>BG</th>\n",
       "      <th>HR</th>\n",
       "      <th>CZ</th>\n",
       "      <th>DK</th>\n",
       "      <th>EE</th>\n",
       "      <th>...</th>\n",
       "      <th>RS</th>\n",
       "      <th>SK</th>\n",
       "      <th>SI</th>\n",
       "      <th>ES</th>\n",
       "      <th>SE</th>\n",
       "      <th>CH</th>\n",
       "      <th>TR</th>\n",
       "      <th>UA</th>\n",
       "      <th>UK</th>\n",
       "      <th>NAO anomaly (Pa)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1964-12-31</th>\n",
       "      <td>-0.208547</td>\n",
       "      <td>6.346964</td>\n",
       "      <td>-1.991219</td>\n",
       "      <td>4.359030</td>\n",
       "      <td>3.280512</td>\n",
       "      <td>4.509862</td>\n",
       "      <td>5.875301</td>\n",
       "      <td>1.121024</td>\n",
       "      <td>2.952823</td>\n",
       "      <td>-2.135660</td>\n",
       "      <td>...</td>\n",
       "      <td>3.777434</td>\n",
       "      <td>1.063379</td>\n",
       "      <td>2.530441</td>\n",
       "      <td>8.698013</td>\n",
       "      <td>-4.506504</td>\n",
       "      <td>-1.423513</td>\n",
       "      <td>6.265606</td>\n",
       "      <td>0.569268</td>\n",
       "      <td>4.910844</td>\n",
       "      <td>-459.574041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1965-12-31</th>\n",
       "      <td>-0.436707</td>\n",
       "      <td>6.254727</td>\n",
       "      <td>-2.671850</td>\n",
       "      <td>4.106645</td>\n",
       "      <td>2.995405</td>\n",
       "      <td>4.087488</td>\n",
       "      <td>5.594632</td>\n",
       "      <td>0.798918</td>\n",
       "      <td>2.700510</td>\n",
       "      <td>-2.763254</td>\n",
       "      <td>...</td>\n",
       "      <td>3.423548</td>\n",
       "      <td>0.714245</td>\n",
       "      <td>2.174084</td>\n",
       "      <td>8.759428</td>\n",
       "      <td>-4.833907</td>\n",
       "      <td>-1.561643</td>\n",
       "      <td>6.234078</td>\n",
       "      <td>-0.000728</td>\n",
       "      <td>4.787535</td>\n",
       "      <td>-690.520941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1966-12-31</th>\n",
       "      <td>-0.442044</td>\n",
       "      <td>6.318606</td>\n",
       "      <td>-2.860769</td>\n",
       "      <td>4.026520</td>\n",
       "      <td>2.985924</td>\n",
       "      <td>4.188005</td>\n",
       "      <td>5.580369</td>\n",
       "      <td>0.706868</td>\n",
       "      <td>2.486880</td>\n",
       "      <td>-3.080792</td>\n",
       "      <td>...</td>\n",
       "      <td>3.448256</td>\n",
       "      <td>0.646428</td>\n",
       "      <td>2.146336</td>\n",
       "      <td>8.733729</td>\n",
       "      <td>-5.048878</td>\n",
       "      <td>-1.602155</td>\n",
       "      <td>6.383782</td>\n",
       "      <td>-0.026194</td>\n",
       "      <td>4.835569</td>\n",
       "      <td>-668.601591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1967-12-31</th>\n",
       "      <td>-0.159168</td>\n",
       "      <td>6.435805</td>\n",
       "      <td>-2.508478</td>\n",
       "      <td>4.350665</td>\n",
       "      <td>3.234064</td>\n",
       "      <td>4.367790</td>\n",
       "      <td>5.859060</td>\n",
       "      <td>1.101616</td>\n",
       "      <td>2.831219</td>\n",
       "      <td>-2.726707</td>\n",
       "      <td>...</td>\n",
       "      <td>3.708023</td>\n",
       "      <td>1.001601</td>\n",
       "      <td>2.535959</td>\n",
       "      <td>8.782863</td>\n",
       "      <td>-4.736100</td>\n",
       "      <td>-1.437711</td>\n",
       "      <td>6.270126</td>\n",
       "      <td>0.252461</td>\n",
       "      <td>5.176834</td>\n",
       "      <td>-603.603464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1968-12-31</th>\n",
       "      <td>0.111201</td>\n",
       "      <td>6.479655</td>\n",
       "      <td>-2.328551</td>\n",
       "      <td>4.473655</td>\n",
       "      <td>3.491886</td>\n",
       "      <td>4.409118</td>\n",
       "      <td>6.064728</td>\n",
       "      <td>1.410646</td>\n",
       "      <td>2.954424</td>\n",
       "      <td>-2.683274</td>\n",
       "      <td>...</td>\n",
       "      <td>3.942778</td>\n",
       "      <td>1.374820</td>\n",
       "      <td>2.764855</td>\n",
       "      <td>8.775518</td>\n",
       "      <td>-4.704557</td>\n",
       "      <td>-1.249916</td>\n",
       "      <td>6.098391</td>\n",
       "      <td>0.381932</td>\n",
       "      <td>5.318128</td>\n",
       "      <td>-487.695747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  AT        AL        BY        BE        BA        BG  \\\n",
       "1964-12-31 -0.208547  6.346964 -1.991219  4.359030  3.280512  4.509862   \n",
       "1965-12-31 -0.436707  6.254727 -2.671850  4.106645  2.995405  4.087488   \n",
       "1966-12-31 -0.442044  6.318606 -2.860769  4.026520  2.985924  4.188005   \n",
       "1967-12-31 -0.159168  6.435805 -2.508478  4.350665  3.234064  4.367790   \n",
       "1968-12-31  0.111201  6.479655 -2.328551  4.473655  3.491886  4.409118   \n",
       "\n",
       "                  HR        CZ        DK        EE  ...        RS        SK  \\\n",
       "1964-12-31  5.875301  1.121024  2.952823 -2.135660  ...  3.777434  1.063379   \n",
       "1965-12-31  5.594632  0.798918  2.700510 -2.763254  ...  3.423548  0.714245   \n",
       "1966-12-31  5.580369  0.706868  2.486880 -3.080792  ...  3.448256  0.646428   \n",
       "1967-12-31  5.859060  1.101616  2.831219 -2.726707  ...  3.708023  1.001601   \n",
       "1968-12-31  6.064728  1.410646  2.954424 -2.683274  ...  3.942778  1.374820   \n",
       "\n",
       "                  SI        ES        SE        CH        TR        UA  \\\n",
       "1964-12-31  2.530441  8.698013 -4.506504 -1.423513  6.265606  0.569268   \n",
       "1965-12-31  2.174084  8.759428 -4.833907 -1.561643  6.234078 -0.000728   \n",
       "1966-12-31  2.146336  8.733729 -5.048878 -1.602155  6.383782 -0.026194   \n",
       "1967-12-31  2.535959  8.782863 -4.736100 -1.437711  6.270126  0.252461   \n",
       "1968-12-31  2.764855  8.775518 -4.704557 -1.249916  6.098391  0.381932   \n",
       "\n",
       "                  UK  NAO anomaly (Pa)  \n",
       "1964-12-31  4.910844       -459.574041  \n",
       "1965-12-31  4.787535       -690.520941  \n",
       "1966-12-31  4.835569       -668.601591  \n",
       "1967-12-31  5.176834       -603.603464  \n",
       "1968-12-31  5.318128       -487.695747  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restrict to NAO anomaly (Pa) column\n",
    "merged_df = merged_df[\"UK\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1964-12-31    4.910844\n",
       "1965-12-31    4.787535\n",
       "1966-12-31    4.835569\n",
       "1967-12-31    5.176834\n",
       "1968-12-31    5.318128\n",
       "Name: UK, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the Series to a DataFrame\n",
    "merged_df = merged_df.to_frame()\n",
    "\n",
    "# Reset the index\n",
    "merged_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the file\n",
    "# # output directory\n",
    "output_dir = \"/home/users/benhutch/NGrid_demand/csv_files\"\n",
    "\n",
    "# output filename\n",
    "output_fname = \"obs_UK_historical_temp_detrend_0.csv\"\n",
    "\n",
    "# Save as a csv file\n",
    "# save the dataframe to a .csv file\n",
    "merged_df.to_csv(os.path.join(output_dir, output_fname), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df, merged_df, merged_df_full, corr_df = dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_df_hdd = merged_df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_df_hdd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfs_ofs_wind = funcs.correlate_nao_uread(\n",
    "#     filename=\"EEZ_zones_wp_historical.nc\",\n",
    "#     nao_n_grid=dicts.uk_n_box_corrected,\n",
    "#     nao_s_grid=dicts.uk_s_box_corrected,\n",
    "#     use_model_data=True,\n",
    "#     model_config=model_config,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(dfs_ofs_wind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _, _, merged_df_full, _ = dfs_ofs_wind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Combine these two datasets together\n",
    "# # HDD - offshore wind\n",
    "# # add suffixes\n",
    "# merged_df_hdd = merged_df_hdd.add_suffix(\"_HDD\")\n",
    "# merged_df_wind = merged_df_full.add_suffix(\"_ofs_wind\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # join the two dataframes\n",
    "# hdd_wind = merged_df_hdd.join(merged_df_wind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hdd_wind.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a new dataframe\n",
    "# demand_net_wind = pd.DataFrame()\n",
    "\n",
    "# # Loop over the columns\n",
    "# for column in hdd_wind.columns:\n",
    "#     if column.endswith('_HDD'):\n",
    "#         country_code = column[:2]  # Get the country code\n",
    "#         if f\"{country_code}_ofs_wind\" in hdd_wind.columns:\n",
    "#             # Standardize the columns before taking the difference\n",
    "#             hdd_standardized = (hdd_wind[column] - hdd_wind[column].mean()) / hdd_wind[column].std()\n",
    "#             ofs_wind_standardized = (hdd_wind[f\"{country_code}_ofs_wind\"] - hdd_wind[f\"{country_code}_ofs_wind\"].mean()) / hdd_wind[f\"{country_code}_ofs_wind\"].std()\n",
    "            \n",
    "#             demand_net_wind[f'{country_code}_diff'] = hdd_standardized - ofs_wind_standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demand_net_wind.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demand_net_wind[\"model_NAO_anomaly_(hPa)\"] = hdd_wind['model_nao_mean_ofs_wind']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.stats import pearsonr\n",
    "\n",
    "# # Create an empty list to store the data\n",
    "# data = []\n",
    "\n",
    "# # Loop over the columns\n",
    "# for column in demand_net_wind.columns:\n",
    "#     if column.endswith('_diff'):\n",
    "#         # Extract the country code\n",
    "#         country_code = column[:2]\n",
    "\n",
    "#         if not demand_net_wind[column].isna().any():\n",
    "#             # Calculate the correlation and p-value\n",
    "#             corr, p_value = pearsonr(demand_net_wind[column], demand_net_wind['model_NAO_anomaly_(hPa)'])\n",
    "        \n",
    "#             # Append the results to the data list\n",
    "#             data.append([country_code, corr, p_value])\n",
    "#         else:\n",
    "#             data.append([country_code, np.nan, np.nan])\n",
    "\n",
    "# # Convert the data list to a dataframe\n",
    "# diff_cor_df = pd.DataFrame(data, columns=['Country Code', 'Correlation', 'P-Value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hdd_wind.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diff_cor_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Rename the columns\n",
    "# corr_df = corr_df.rename(columns={\n",
    "#     \"correlation\": \"correlation_(hc_nao, onshore_cfs)\",\n",
    "#     \"p-value\": \"p-value_(hc_nao, onshore_cfs)\"\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demand_net_wind.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the data but using delta P instead of the NAO index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nao_df_dir = \"/gws/nopw/j04/canari/users/benhutch/nao_stats_df/\"\n",
    "# nao_df_fname = \"psl_ONDJFM_global_1961_2014_2-9_4_nao_default.csv\"\n",
    "\n",
    "# # # Set up the model config\n",
    "# # model_config = {\n",
    "# #     \"variable\": \"psl\",\n",
    "# #     \"season\": \"ONDJFM\",\n",
    "# #     \"region\": \"global\",\n",
    "# #     \"start_year\": 1961,\n",
    "# #     \"end_year\": 2014,\n",
    "# #     \"forecast_range\": \"2-9\",\n",
    "# #     \"lag\": 4,\n",
    "# #     \"nao\": \"thornton_2019_uk\",\n",
    "# # }\n",
    "\n",
    "# # Set up the model config\n",
    "# model_config = {\n",
    "#     \"variable\": \"psl\",\n",
    "#     \"season\": \"ONDJFM\",\n",
    "#     \"region\": \"global\",\n",
    "#     \"start_year\": 1961,\n",
    "#     \"end_year\": 2014,\n",
    "#     \"forecast_range\": \"2-9\",\n",
    "#     \"lag\": 4,\n",
    "#     \"nao\": \"thornton_2019_uk\",\n",
    "#     \"gridbox\": \"Scandinavia\",\n",
    "#     \"method\": \"nao_matched\",\n",
    "# }\n",
    "\n",
    "\n",
    "# # EEZ_zones_wp_historical.nc\n",
    "# # NUTS_0_HDD_historical_pop_weighted.nc\n",
    "# # test the other function for doing this\n",
    "# # days for cooling degree days\n",
    "# df, merged_df, merged_df_full, corr_df = funcs.correlate_nao_uread(\n",
    "#     filename=\"NUTS_0_HDD_historical_pop_weighted.nc\",\n",
    "#     time_unit=\"d\",\n",
    "#     obs_var=\"msl\",\n",
    "#     avg_grid=dicts.scandi_box,\n",
    "#     use_model_data=True,\n",
    "#     model_config=model_config,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calib_df = funcs.calc_model_nao_gridbox_var_corr(\n",
    "#     nao_df=merged_df_full,\n",
    "#     gridbox=dicts.med_box_focus,\n",
    "#     obs_var=\"ssrd\",\n",
    "#     obs_var_data_path=dicts.regrid_file,\n",
    "#     coeff_fname=\"obs_nao_obs_solar_cfs_slope.csv\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calib_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # reload the functions\n",
    "# import importlib\n",
    "\n",
    "# importlib.reload(funcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test the plotting function\n",
    "# funcs.plot_calib_corr(\n",
    "#     df=calib_df,\n",
    "#     predictand_var=\"ES\",\n",
    "#     index_name=\"Calibrated NAO (hPa)\",\n",
    "#     ylabel=\"Spain solar CF.'s (GW)\",\n",
    "#     zero_line=False,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot the calibrated_model_nao_mean against the var228 anomaly mean\n",
    "# # with seperate y-axes\n",
    "# from scipy.stats import pearsonr\n",
    "\n",
    "# # Create a new figure and an axes\n",
    "# fig, ax1 = plt.subplots()\n",
    "\n",
    "# # Plot the calibrated_model_nao_mean on the first y-axis\n",
    "# ax1.plot(df.index, df[\"calibrated_model_nao_mean\"], color=\"blue\", label=\"nao\")\n",
    "# ax1.set_ylabel(\"pr anomalies (mm/day)\")\n",
    "# # Plot the var228 anomaly mean on the second y-axis\n",
    "# ax1.plot(df.index, df[\"var228 anomaly mean\"], color=\"red\", label=\"var228\")\n",
    "\n",
    "# # show the correlation coefiients\n",
    "# corr, p = pearsonr(df[\"calibrated_model_nao_mean\"], df[\"var228 anomaly mean\"])\n",
    "\n",
    "# # Include a textbox in the top left hand corner with the corr and p values\n",
    "# plt.text(\n",
    "#     0.05,\n",
    "#     0.95,\n",
    "#     f\"Corr: {round(corr, 2)}\\n p-value: {round(p, 2)}\",\n",
    "#     horizontalalignment=\"left\",\n",
    "#     verticalalignment=\"top\",\n",
    "#     transform=plt.gca().transAxes,\n",
    "#     bbox=dict(facecolor=\"white\", alpha=0.5),\n",
    "# )\n",
    "\n",
    "# # Include a horixzontal black dashed line at y=0\n",
    "# plt.axhline(0, color=\"black\", linestyle=\"--\")\n",
    "\n",
    "# # Include a legend\n",
    "# plt.legend(loc=\"upper right\")\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"{p:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the NUTS shapefiles\n",
    "# Load in the shapefile fo the eez data\n",
    "NUTS_shapefile = gpd.read_file(\"~/shapefiles/NUTS/NUTS_RG_10M_2021_4326.shp\")\n",
    "\n",
    "# Restrict to level code 0\n",
    "NUTS_shapefile = NUTS_shapefile[NUTS_shapefile.LEVL_CODE == 0]\n",
    "\n",
    "# Extract the second element of the tuple\n",
    "countries_codes = list(dicts.countries_nuts_id.values())\n",
    "\n",
    "# Limit the gpd to the countries in the dictionary\n",
    "NUTS_shapefile = NUTS_shapefile[NUTS_shapefile.NUTS_ID.isin(countries_codes)]\n",
    "\n",
    "# Keep only the NUTS_ID, NUTS_NAME, and geometry columns\n",
    "NUTS_shapefile = NUTS_shapefile[[\"NUTS_ID\", \"NUTS_NAME\", \"geometry\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUTS_shapefile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the shapefile fo the eez data\n",
    "EEZ_shapefile = gpd.read_file(\"~/shapefiles/EEZ/eez_v12.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EEZ_shapefile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Print all of the column names for the eeZ shapefile\n",
    "# print(EEZ_shapefile.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Throw away all of the columns, apart from \"GEONAME\", 'SOVEREIGN1',\n",
    "# \"ISOSOV1\", \"geometry\"\n",
    "EEZ_shapefile = EEZ_shapefile[[\"GEONAME\", \"SOVEREIGN1\", \"ISO_SOV1\", \"geometry\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EEZ_shapefile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iso_sov1 = EEZ_shapefile[\"ISO_SOV1\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iso_sov1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the values of the region column from corr_df\n",
    "region_values = corr_df.region.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload the dictionary\n",
    "importlib.reload(dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the region values to equivalent iso_sov1 values\n",
    "# using the mapping in the dictionary\n",
    "iso_sov1_values = [dicts.iso_mapping[region] for region in region_values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iso_sov1_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constrain the geo dataframe to only include the iso_sov1 values\n",
    "EEZ_shapefile = EEZ_shapefile[EEZ_shapefile[\"ISO_SOV1\"].isin(iso_sov1_values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find where ISO_SOV1 is equal to \"ITA\"\n",
    "EEZ_shapefile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where corr_df.region passed through iso_mapping dict is\n",
    "# equal to the values in EEZ_shapefile.ISO_SOV1\n",
    "# Add the corresponding correlation and p-value to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter df to only include the rows where GEONAME includes: \"Exclusive Economic Zone\"\n",
    "EEZ_shapefile = EEZ_shapefile[\n",
    "    EEZ_shapefile[\"GEONAME\"].str.contains(\"Exclusive Economic Zone\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EEZ_shapefile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we want to append the correlation and p-value to the dataframe\n",
    "# Add a new column to corr_df called \"ISO_SOV1\"\n",
    "corr_df[\"ISO_SOV1\"] = iso_sov1_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df[\"region\"] == \"EL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over the columns in EEZ_shapefile and add the correlation and p-value\n",
    "# where the ISO_SOV1 values are equal\n",
    "for index, row in EEZ_shapefile.iterrows():\n",
    "    # Extract the ISO_SOV1 value\n",
    "    iso_sov1 = row[\"ISO_SOV1\"]\n",
    "    # Find the index of the row in corr_df that matches the ISO_SOV1\n",
    "    index_corr = corr_df[corr_df[\"ISO_SOV1\"] == iso_sov1].index\n",
    "    # Add the correlation and p-value to the dataframe\n",
    "    EEZ_shapefile.loc[index, \"correlation\"] = corr_df.loc[\n",
    "        index_corr, \"correlation\"\n",
    "    ].values\n",
    "    EEZ_shapefile.loc[index, \"p-value\"] = corr_df.loc[index_corr, \"p-value\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same thing for the NUTS_shapefile\n",
    "for index, row in NUTS_shapefile.iterrows():\n",
    "    # Extract the NUTS_ID value\n",
    "    nuts_id = row[\"NUTS_ID\"]\n",
    "\n",
    "    # Find the index of the row in corr_df that matches the NUTS_ID\n",
    "    index_corr = corr_df[corr_df[\"region\"] == nuts_id].index\n",
    "\n",
    "    if len(index_corr) == 0:\n",
    "        print(f\"No match found for {nuts_id}\")\n",
    "        continue\n",
    "\n",
    "    # Add the correlation and p-value to the dataframe\n",
    "    NUTS_shapefile.loc[index, \"correlation\"] = corr_df.loc[\n",
    "        index_corr, \"correlation\"\n",
    "    ].values\n",
    "\n",
    "    NUTS_shapefile.loc[index, \"p-value\"] = corr_df.loc[index_corr, \"p-value\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EEZ_shapefile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUTS_shapefile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any rows from EEZ shapefile which contain \"(*)\" in the GEONAME column\n",
    "EEZ_shapefile = EEZ_shapefile[~EEZ_shapefile[\"GEONAME\"].str.contains(r\"\\(.*\\)\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EEZ_shapefile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(EEZ_shapefile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the dicts\n",
    "importlib.reload(dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "# Now plot the EEZ_shapefile with the correlation as the color\n",
    "plt.figure(figsize=(10, 10))\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "EEZ_shapefile.plot(\n",
    "    column=\"correlation\",\n",
    "    ax=ax,\n",
    "    legend=True,\n",
    "    cmap=\"coolwarm\",\n",
    "    vmin=-1,\n",
    "    vmax=1,\n",
    "    legend_kwds={\n",
    "        \"label\": \"Correlation\",\n",
    "        \"orientation\": \"horizontal\",\n",
    "        \"shrink\": 0.8,\n",
    "        \"pad\": 0.01,\n",
    "    },\n",
    ")\n",
    "# Use cartopy to add the coastlines\n",
    "ax.coastlines()\n",
    "# Make the colorbar smaller\n",
    "cbar = ax.get_figure().get_axes()[1]\n",
    "cbar.set_ylabel(\"Correlation\", fontsize=12)\n",
    "cbar.tick_params(labelsize=10)\n",
    "\n",
    "# Extract the lats of the northern eu grid box\n",
    "lat1, lat2 = dicts.med_box_focus[\"lat1\"], dicts.med_box_focus[\"lat2\"]\n",
    "lon1, lon2 = dicts.med_box_focus[\"lon1\"], dicts.med_box_focus[\"lon2\"]\n",
    "\n",
    "# # Plot the grid box\n",
    "# plt.plot([lon1, lon2, lon2, lon1, lon1], [lat1, lat1, lat2, lat2, lat1], \"r\")\n",
    "\n",
    "# Include hazels grid box\n",
    "lat1_n, lat2_n = (\n",
    "    dicts.uk_n_box_corrected[\"lat1\"],\n",
    "    dicts.uk_n_box_corrected[\"lat2\"],\n",
    ")\n",
    "lon1_n, lon2_n = (\n",
    "    dicts.uk_n_box_corrected[\"lon1\"],\n",
    "    dicts.uk_n_box_corrected[\"lon2\"],\n",
    ")\n",
    "\n",
    "#Plot the grid box\n",
    "plt.plot(\n",
    "    [lon1_n, lon2_n, lon2_n, lon1_n, lon1_n],\n",
    "    [lat1_n, lat1_n, lat2_n, lat2_n, lat1_n],\n",
    "    \"g\",\n",
    "    label=\"delta P\",\n",
    ")\n",
    "\n",
    "# Include hazels grid box\n",
    "lat1_s, lat2_s = (\n",
    "    dicts.uk_s_box_corrected[\"lat1\"],\n",
    "    dicts.uk_s_box_corrected[\"lat2\"],\n",
    ")\n",
    "lon1_s, lon2_s = (\n",
    "    dicts.uk_s_box_corrected[\"lon1\"],\n",
    "    dicts.uk_s_box_corrected[\"lon2\"],\n",
    ")\n",
    "\n",
    "# Plot the grid box\n",
    "plt.plot(\n",
    "    [lon1_s, lon2_s, lon2_s, lon1_s, lon1_s],\n",
    "    [lat1_s, lat1_s, lat2_s, lat2_s, lat1_s],\n",
    "    \"g\",\n",
    ")\n",
    "\n",
    "# Include ticks for the lat and lon\n",
    "ax.gridlines(draw_labels=True)\n",
    "\n",
    "# include a legend\n",
    "plt.legend()\n",
    "\n",
    "# north_atlantic_grid_plot = {\"lon1\": -15, \"lon2\": 40, \"lat1\": 35, \"lat2\": 80}\n",
    "\n",
    "# Constrain to specific bounds\n",
    "ax.set_xlim(-40, 40)\n",
    "ax.set_ylim(32, 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the dictionary\n",
    "importlib.reload(dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit the EEZ_shapefile to only include only the ISO_SOV1 values\n",
    "# Which are in dicts.eez_agg_countries\n",
    "EEZ_shapefile_n = EEZ_shapefile[EEZ_shapefile[\"ISO_SOV1\"].isin(dicts.eez_agg_countries)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now plot the EEZ_shapefile with the correlation as the color\n",
    "plt.figure(figsize=(10, 10))\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "EEZ_shapefile_n.plot(\n",
    "    column=\"correlation\",\n",
    "    ax=ax,\n",
    "    legend=True,\n",
    "    cmap=\"bwr\",\n",
    "    vmin=-1,\n",
    "    vmax=1,\n",
    "    legend_kwds={\n",
    "        \"label\": \"Pearson correlation with ONDJFM delta P index\",\n",
    "        \"orientation\": \"horizontal\",\n",
    "        \"shrink\": 0.8,\n",
    "        \"pad\": 0.01,\n",
    "    },\n",
    ")\n",
    "# Use cartopy to add the coastlines\n",
    "ax.coastlines()\n",
    "# Make the colorbar smaller\n",
    "cbar = ax.get_figure().get_axes()[1]\n",
    "cbar.set_ylabel(\"Pearson correlation with delta P index\", fontsize=12)\n",
    "cbar.tick_params(labelsize=10)\n",
    "\n",
    "# Include ticks for the lat and lon\n",
    "ax.gridlines(draw_labels=True, alpha=0.5)\n",
    "\n",
    "# Constrain to specific bounds\n",
    "ax.set_xlim(-30, 40)\n",
    "ax.set_ylim(40, 80)\n",
    "\n",
    "# Set up the fname\n",
    "fname = \"N_europe_regions_corr_delta_P.pdf\"\n",
    "fpath = \"/gws/nopw/j04/canari/users/benhutch/plots\"\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig(os.path.join(fpath,fname),dpi=600)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload dicts\n",
    "importlib.reload(dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a new column in cfs called N_Europe\n",
    "# # which is the average of all of the countries (columns) in dicts.eez_agg_countries\n",
    "# # Convert to three character names first\n",
    "# for key in dicts.iso_mapping:\n",
    "#     merged_df_full = merged_df_full.rename(columns={key: dicts.iso_mapping[key]})\n",
    "\n",
    "# merged_df_full[\"N_Europe\"] = merged_df_full[dicts.eez_agg_countries].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demand_net_wind.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload functions\n",
    "importlib.reload(funcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the plotting function\n",
    "funcs.plot_time_series(\n",
    "    df=merged_df,\n",
    "    predictor_col=\"NAO anomaly (Pa)\",\n",
    "    predictand_col=\"UK\",\n",
    "    ylabel=\"Normalised anomaly\",\n",
    "    figsize_x=10,\n",
    "    figsize_y=5,\n",
    "    twin_axes=False,\n",
    "    do_detrend_predictor=True,\n",
    "    do_detrend_predictand=True,\n",
    "    normalise_anom=True,\n",
    "    title=\"Observed delta P index (black, detrended) and\\n UK historical temperature (blue, detrended)\",\n",
    "    label=\"a\",\n",
    "    fontsize=10,\n",
    "    predictor_color=\"k\",\n",
    "    predictand_color=\"b\",\n",
    "    inverse_predictand=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Create a plot with two y-axes\n",
    "# Time on the x-axes\n",
    "# The variable on the left y-axes is the NAO anomaly (Pa)\n",
    "# The variable on the right y-axes is the wind power (GW) for N_Europe\n",
    "fig, ax1 = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "# Plot the NAO anomaly\n",
    "ax1.plot(merged_df_full.index, merged_df_full.model_nao_mean / 100, \"b-\")\n",
    "\n",
    "# Set the x-axis label\n",
    "ax1.set_xlabel(\"Time\")\n",
    "\n",
    "# Set the y-axis label\n",
    "ax1.set_ylabel(\"Hindcast NAO anomaly (hPa)\", color=\"b\")\n",
    "\n",
    "# Include a black dashed line for y=0\n",
    "ax1.axhline(0, color=\"black\", linestyle=\"--\")\n",
    "\n",
    "# Set the color of the ticks\n",
    "ax1.tick_params(\"y\", colors=\"b\")\n",
    "\n",
    "# Create a second y-axis\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "# Plot the wind power\n",
    "ax2.plot(merged_df_full.index, merged_df_full.ES, \"r-\")\n",
    "\n",
    "# Set the y-axis label\n",
    "ax2.set_ylabel(\"Spain solar CFs\", color=\"r\")\n",
    "\n",
    "# Set the colour of the ticks\n",
    "ax2.tick_params(\"y\", colors=\"r\")\n",
    "\n",
    "# # Invert the y-axis\n",
    "# ax2.invert_yaxis()\n",
    "\n",
    "# Calculate the correlation between the NAO anomaly and the wind power\n",
    "corr, p = pearsonr(merged_df_full.model_nao_mean, merged_df_full.ES)\n",
    "\n",
    "# Include the correlation and p-value on the plot\n",
    "ax2.text(\n",
    "    0.05,\n",
    "    0.95,\n",
    "    f\"Correlation: {corr:.2f}\\nP-value: {p:.2f}\",\n",
    "    horizontalalignment=\"left\",\n",
    "    verticalalignment=\"top\",\n",
    "    bbox=dict(facecolor=\"white\", alpha=0.5),\n",
    "    transform=ax2.transAxes,\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdd_wind.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import linregress\n",
    "\n",
    "# Plot a scatter plot of NAO agaist wind power\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "# Plot the scatter plot\n",
    "plt.scatter(hdd_wind.UK_HDD_HDD, hdd_wind.UK_ofs_wind, color=\"k\")\n",
    "\n",
    "# Include a line of best fit\n",
    "slope, intercept, r_value, p_value, std_err = linregress(\n",
    "    hdd_wind.UK_HDD_HDD, hdd_wind.UK_ofs_wind\n",
    ")\n",
    "\n",
    "# Plot the line of best fit\n",
    "plt.plot(\n",
    "    hdd_wind.UK_HDD_HDD,\n",
    "    slope * hdd_wind.UK_HDD_HDD+ intercept,\n",
    "    color=\"k\",\n",
    ")\n",
    "\n",
    "# Show the values\n",
    "if intercept < 0:\n",
    "    equation = f\"y = {slope:.2f}x - {abs(intercept):.3f}\"\n",
    "else:\n",
    "    equation = f\"y = {slope:.2f}x + {intercept:.3f}\"\n",
    "\n",
    "plt.text(\n",
    "    0.05,\n",
    "    0.95,\n",
    "    f\"{equation}\\nr={r_value:.2f}, p={p_value:.2f}\",\n",
    "    horizontalalignment=\"left\",\n",
    "    verticalalignment=\"top\",\n",
    "    transform=plt.gca().transAxes,\n",
    "    bbox=dict(facecolor=\"white\", alpha=0.5),\n",
    ")\n",
    "\n",
    "# Set the x-axis label\n",
    "plt.xlabel(\"Observed UK HDD\", color=\"k\", fontsize=14)\n",
    "\n",
    "# Set the xticks to blue\n",
    "plt.tick_params(axis=\"x\", colors=\"k\")\n",
    "\n",
    "# Set the y-axis label\n",
    "plt.ylabel(\"Observed UK offshore wind CFs\", color=\"k\", fontsize=14)\n",
    "\n",
    "# Include a textbox in the bottom right\n",
    "plt.text(\n",
    "    0.95,\n",
    "    0.05,\n",
    "    f\"d\",\n",
    "    fontsize=12,\n",
    "    transform=plt.gca().transAxes,\n",
    "    verticalalignment=\"bottom\",\n",
    "    horizontalalignment=\"right\",\n",
    "    bbox=dict(facecolor=\"white\", alpha=0.5),\n",
    ")\n",
    "\n",
    "# Set the yticks to red\n",
    "plt.tick_params(axis=\"y\", colors=\"k\")\n",
    "\n",
    "# save this as a pdf\n",
    "filename = \"scatter_delta_p_uk_demand_net_wind.pdf\"\n",
    "dir = \"/gws/nopw/j04/canari/users/benhutch/plots/\"\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig(f\"{dir}{filename}\",dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a dataframe to store the values\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"slope\": [slope],\n",
    "        \"intercept\": [intercept],\n",
    "        \"r_value\": [r_value],\n",
    "        \"p_value\": [p_value],\n",
    "        \"std_err\": [std_err],\n",
    "    }\n",
    ")\n",
    "\n",
    "# Set up a filename for the dataframe\n",
    "dir = \"/home/users/benhutch/energy-met-corr/coeffs\"\n",
    "\n",
    "# If the directory does not exist, create it\n",
    "if not os.path.exists(dir):\n",
    "    os.makedirs(dir)\n",
    "\n",
    "# Set up the filename\n",
    "fname = \"obs_nao_obs_solar_cfs_slope.csv\"\n",
    "\n",
    "# set up the full path\n",
    "fpath = os.path.join(dir, fname)\n",
    "\n",
    "# Save the datafram\n",
    "df.to_csv(fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the ERA5 data for the NAO index\n",
    "# Use this file\n",
    "# adaptor.mars.internal-1691509121.3261805-29348-4-3a487c76-fc7b-421f-b5be-7436e2eb78d7.nc\n",
    "# in ~/ERA5/\n",
    "# Load the dataset\n",
    "era5_data_path = \"~/ERA5/adaptor.mars.internal-1691509121.3261805-29348-4-3a487c76-fc7b-421f-b5be-7436e2eb78d7.nc\"\n",
    "\n",
    "# Load the data into chunks\n",
    "ds_era5 = xr.open_mfdataset(\n",
    "    era5_data_path,\n",
    "    combine=\"by_coords\",\n",
    "    parallel=True,\n",
    "    chunks={\"time\": 100, \"latitude\": 100, \"longitude\": 100},\n",
    ")[\n",
    "    \"msl\"\n",
    "]  # for mean sea level pressure\n",
    "\n",
    "# Combine the first two expver variables\n",
    "obs_msl = ds_era5.sel(expver=1).combine_first(ds_era5.sel(expver=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constrain obs to ONDJFM\n",
    "obs_msl = obs_msl.sel(time=obs_msl.time.dt.month.isin([10, 11, 12, 1, 2, 3]))\n",
    "\n",
    "# Shift the time index back by 3 months\n",
    "obs_msl_shifted = obs_msl.shift(time=-3)\n",
    "\n",
    "# Take annual means\n",
    "obs_msl_annual = obs_msl_shifted.resample(time=\"Y\").mean()\n",
    "\n",
    "# Throw away years 1959, 2021, 2022 and 2023\n",
    "obs_msl_annual = obs_msl_annual.sel(time=slice(\"1960\", \"2019\"))\n",
    "\n",
    "# Remove the climatology\n",
    "obs_msl_anomaly = obs_msl_annual - obs_msl_annual.mean(dim=\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the lats and lons of the azores\n",
    "lat1, lat2 = dicts.era5_azores[\"lat1\"], dicts.era5_azores[\"lat2\"]\n",
    "lon1, lon2 = dicts.era5_azores[\"lon1\"], dicts.era5_azores[\"lon2\"]\n",
    "\n",
    "# Calculate the mean for the azores gridbox\n",
    "obs_msl_anomaly_azores = obs_msl_anomaly.sel(\n",
    "    latitude=slice(lat1, lat2), longitude=slice(lon1, lon2)\n",
    ").mean(dim=[\"latitude\", \"longitude\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same for iceland\n",
    "lat1, lat2 = dicts.era5_iceland[\"lat1\"], dicts.era5_iceland[\"lat2\"]\n",
    "lon1, lon2 = dicts.era5_iceland[\"lon1\"], dicts.era5_iceland[\"lon2\"]\n",
    "\n",
    "# Calculate the mean for the iceland gridbox\n",
    "obs_msl_anomaly_iceland = obs_msl_anomaly.sel(\n",
    "    latitude=slice(lat1, lat2), longitude=slice(lon1, lon2)\n",
    ").mean(dim=[\"latitude\", \"longitude\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the NAO index (azores - iceland)\n",
    "nao_index = obs_msl_anomaly_azores - obs_msl_anomaly_iceland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXtract the time series\n",
    "nao_index_time = nao_index.time.values\n",
    "\n",
    "# Extract the values\n",
    "nao_index_values = nao_index.values\n",
    "\n",
    "# Create a dataframe\n",
    "nao_df = pd.DataFrame({\"time\": nao_index_time, \"value\": nao_index_values})\n",
    "\n",
    "# Take a centred 8-year running mean\n",
    "nao_running = nao_df.set_index(\"time\").rolling(8, center=True).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have a look at the dataframe\n",
    "nao_running.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the NaN values\n",
    "nao_running = nao_running.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the two dataframes into one, using the index of the first\n",
    "eez_df = eez_cfs.join(nao_running, how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eez_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the value column as 'NAO anomaly (Pa)'\n",
    "eez_df = eez_df.rename(columns={\"value\": \"NAO anomaly (Pa)\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the rows which contain NaN values in the NAO anomaly column\n",
    "eez_df = eez_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eez_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "import pandas as pd\n",
    "\n",
    "# Create a new dataframe with columns for:\n",
    "# 'region' - e.g. Netherlands_7\n",
    "# 'correlation' - the correlation between the NAO and the offshore wind CFs\n",
    "# 'p-value' - the p-value of the correlation\n",
    "# Set up the dataframe\n",
    "correlation_df = pd.DataFrame(columns=[\"region\", \"correlation\", \"p-value\"])\n",
    "\n",
    "# Loop over the regions\n",
    "for region in eez_df.columns[:-1]:\n",
    "    # Calculate the correlation\n",
    "    corr, p = pearsonr(eez_df[region], eez_df[\"NAO anomaly (Pa)\"])\n",
    "\n",
    "    # Create a new DataFrame to append\n",
    "    df_to_append = pd.DataFrame(\n",
    "        {\"region\": [region], \"correlation\": [corr], \"p-value\": [p]}\n",
    "    )\n",
    "\n",
    "    # Append to the dataframe\n",
    "    correlation_df = pd.concat([correlation_df, df_to_append], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the numbers from the region column by removing the last 2 characters\n",
    "correlation_df[\"region\"] = correlation_df[\"region\"].str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if any of the region names contain the string \"_\" then remove it\n",
    "correlation_df[\"region\"] = correlation_df[\"region\"].str.replace(\"_\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EEZ_shapefile[\"SOVEREIGN1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two new columns in the geopandas dataframe 'EEZ_shapefile'\n",
    "# 'correlation' - the correlation between the NAO and the offshore wind CFs\n",
    "# 'p-value' - the p-value of the correlation\n",
    "EEZ_shapefile[\"correlation\"] = np.nan\n",
    "EEZ_shapefile[\"p-value\"] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EEZ_shapefile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over the regions in correlation_df\n",
    "for region in correlation_df[\"region\"]:\n",
    "    # Extract the row from correlation_df\n",
    "    row = correlation_df[correlation_df[\"region\"] == region]\n",
    "\n",
    "    # Extract the correlation and p-value\n",
    "    corr = row[\"correlation\"].values[0]\n",
    "    p = row[\"p-value\"].values[0]\n",
    "\n",
    "    # Set the values in the EEZ_shapefile\n",
    "    EEZ_shapefile.loc[EEZ_shapefile[\"TERRITORY1\"] == region, \"correlation\"] = corr\n",
    "    EEZ_shapefile.loc[EEZ_shapefile[\"TERRITORY1\"] == region, \"p-value\"] = p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EEZ_shapefile[\"TERRITORY1\"] == \"France\", \"correlation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the list of Terrirories\n",
    "territories = EEZ_shapefile[\"TERRITORY1\"]\n",
    "\n",
    "# Convert to a list\n",
    "territories = list(territories)\n",
    "\n",
    "# Print the territories\n",
    "print(territories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constrain EEZ shapefile to only include the territories in the list\n",
    "EEZ_shapefile = EEZ_shapefile[EEZ_shapefile[\"TERRITORY1\"].isin(dicts.countries_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the correlation values for FRance\n",
    "print(EEZ_shapefile[EEZ_shapefile[\"SOVEREIGN1\"] == \"France\"][\"correlation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "# Now plot the EEZ_shapefile with the correlation as the color\n",
    "plt.figure(figsize=(10, 10))\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "EEZ_shapefile.plot(\n",
    "    column=\"correlation\", ax=ax, legend=True, cmap=\"coolwarm\", shrink=0.5\n",
    ")\n",
    "# Use cartopy to add the coastlines\n",
    "ax.coastlines()\n",
    "# Make the colorbar smaller\n",
    "cbar = ax.get_figure().get_axes()[1]\n",
    "cbar.set_ylabel(\"Correlation\", fontsize=12)\n",
    "cbar.tick_params(labelsize=10)\n",
    "\n",
    "# Constrain to specific bounds\n",
    "ax.set_xlim(-50, 50)\n",
    "ax.set_ylim(30, 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now plot the EEZ_shapefile with the correlation as the color\n",
    "fig, ax = plt.subplots(figsize=(10, 10), subplot_kw={\"projection\": ccrs.PlateCarree()})\n",
    "cax = EEZ_shapefile.plot(\n",
    "    column=\"correlation\", ax=ax, cmap=\"coolwarm\", add_colorbar=False\n",
    ")\n",
    "\n",
    "# Use cartopy to add the coastlines\n",
    "ax.coastlines()\n",
    "\n",
    "# Add colorbar\n",
    "cbar = fig.colorbar(cax.collections[0], ax=ax, shrink=0.5)\n",
    "cbar.set_label(\"Correlation\")\n",
    "\n",
    "# Constrain to specific bounds\n",
    "ax.set_xlim(-50, 50)\n",
    "ax.set_ylim(30, 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bens-python-environment",
   "language": "python",
   "name": "bens-python-environment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
