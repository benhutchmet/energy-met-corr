{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the relevant modules\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "\n",
    "# Import third party modules\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dictionaries_em as dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the NUTS shapefiles\n",
    "# Load in the shapefile fo the eez data\n",
    "NUTS_shapefile = gpd.read_file(\"~/shapefiles/NUTS/NUTS_RG_10M_2021_4326.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NUTS_ID</th>\n",
       "      <th>LEVL_CODE</th>\n",
       "      <th>CNTR_CODE</th>\n",
       "      <th>NAME_LATN</th>\n",
       "      <th>NUTS_NAME</th>\n",
       "      <th>MOUNT_TYPE</th>\n",
       "      <th>URBN_TYPE</th>\n",
       "      <th>COAST_TYPE</th>\n",
       "      <th>FID</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BG423</td>\n",
       "      <td>3</td>\n",
       "      <td>BG</td>\n",
       "      <td>Pazardzhik</td>\n",
       "      <td>Пазарджик</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>BG423</td>\n",
       "      <td>POLYGON ((24.42101 42.55306, 24.41032 42.46950...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BG424</td>\n",
       "      <td>3</td>\n",
       "      <td>BG</td>\n",
       "      <td>Smolyan</td>\n",
       "      <td>Смолян</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>BG424</td>\n",
       "      <td>POLYGON ((25.07422 41.79348, 25.05851 41.75177...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BG425</td>\n",
       "      <td>3</td>\n",
       "      <td>BG</td>\n",
       "      <td>Kardzhali</td>\n",
       "      <td>Кърджали</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>BG425</td>\n",
       "      <td>POLYGON ((25.94863 41.32034, 25.90644 41.30757...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CH011</td>\n",
       "      <td>3</td>\n",
       "      <td>CH</td>\n",
       "      <td>Vaud</td>\n",
       "      <td>Vaud</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>CH011</td>\n",
       "      <td>MULTIPOLYGON (((6.86623 46.90929, 6.89621 46.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CH012</td>\n",
       "      <td>3</td>\n",
       "      <td>CH</td>\n",
       "      <td>Valais</td>\n",
       "      <td>Valais</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>CH012</td>\n",
       "      <td>POLYGON ((8.47767 46.52760, 8.39953 46.48872, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  NUTS_ID  LEVL_CODE CNTR_CODE   NAME_LATN  NUTS_NAME  MOUNT_TYPE  URBN_TYPE  \\\n",
       "0   BG423          3        BG  Pazardzhik  Пазарджик         3.0          2   \n",
       "1   BG424          3        BG     Smolyan     Смолян         3.0          3   \n",
       "2   BG425          3        BG   Kardzhali   Кърджали         3.0          3   \n",
       "3   CH011          3        CH        Vaud       Vaud         3.0          2   \n",
       "4   CH012          3        CH      Valais     Valais         3.0          2   \n",
       "\n",
       "   COAST_TYPE    FID                                           geometry  \n",
       "0           3  BG423  POLYGON ((24.42101 42.55306, 24.41032 42.46950...  \n",
       "1           3  BG424  POLYGON ((25.07422 41.79348, 25.05851 41.75177...  \n",
       "2           3  BG425  POLYGON ((25.94863 41.32034, 25.90644 41.30757...  \n",
       "3           3  CH011  MULTIPOLYGON (((6.86623 46.90929, 6.89621 46.9...  \n",
       "4           3  CH012  POLYGON ((8.47767 46.52760, 8.39953 46.48872, ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUTS_shapefile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restrict to level code 0\n",
    "NUTS_shapefile = NUTS_shapefile[NUTS_shapefile.LEVL_CODE == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NUTS_ID</th>\n",
       "      <th>LEVL_CODE</th>\n",
       "      <th>CNTR_CODE</th>\n",
       "      <th>NAME_LATN</th>\n",
       "      <th>NUTS_NAME</th>\n",
       "      <th>MOUNT_TYPE</th>\n",
       "      <th>URBN_TYPE</th>\n",
       "      <th>COAST_TYPE</th>\n",
       "      <th>FID</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1901</th>\n",
       "      <td>AL</td>\n",
       "      <td>0</td>\n",
       "      <td>AL</td>\n",
       "      <td>Shqipëria</td>\n",
       "      <td>Shqipëria</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>AL</td>\n",
       "      <td>POLYGON ((19.82698 42.46950, 19.83939 42.46950...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1902</th>\n",
       "      <td>AT</td>\n",
       "      <td>0</td>\n",
       "      <td>AT</td>\n",
       "      <td>Österreich</td>\n",
       "      <td>Österreich</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>AT</td>\n",
       "      <td>POLYGON ((15.54245 48.90770, 15.75363 48.85218...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1903</th>\n",
       "      <td>BE</td>\n",
       "      <td>0</td>\n",
       "      <td>BE</td>\n",
       "      <td>Belgique/België</td>\n",
       "      <td>Belgique/België</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BE</td>\n",
       "      <td>POLYGON ((5.10218 51.42900, 5.08780 51.38230, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1916</th>\n",
       "      <td>DK</td>\n",
       "      <td>0</td>\n",
       "      <td>DK</td>\n",
       "      <td>Danmark</td>\n",
       "      <td>Danmark</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>DK</td>\n",
       "      <td>MULTIPOLYGON (((14.82540 55.25410, 14.94371 55...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1920</th>\n",
       "      <td>DE</td>\n",
       "      <td>0</td>\n",
       "      <td>DE</td>\n",
       "      <td>Deutschland</td>\n",
       "      <td>Deutschland</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>DE</td>\n",
       "      <td>MULTIPOLYGON (((9.42015 54.83196, 9.42293 54.8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     NUTS_ID  LEVL_CODE CNTR_CODE        NAME_LATN        NUTS_NAME  \\\n",
       "1901      AL          0        AL        Shqipëria        Shqipëria   \n",
       "1902      AT          0        AT       Österreich       Österreich   \n",
       "1903      BE          0        BE  Belgique/België  Belgique/België   \n",
       "1916      DK          0        DK          Danmark          Danmark   \n",
       "1920      DE          0        DE      Deutschland      Deutschland   \n",
       "\n",
       "      MOUNT_TYPE  URBN_TYPE  COAST_TYPE FID  \\\n",
       "1901         0.0          0           0  AL   \n",
       "1902         0.0          0           0  AT   \n",
       "1903         0.0          0           0  BE   \n",
       "1916         0.0          0           0  DK   \n",
       "1920         0.0          0           0  DE   \n",
       "\n",
       "                                               geometry  \n",
       "1901  POLYGON ((19.82698 42.46950, 19.83939 42.46950...  \n",
       "1902  POLYGON ((15.54245 48.90770, 15.75363 48.85218...  \n",
       "1903  POLYGON ((5.10218 51.42900, 5.08780 51.38230, ...  \n",
       "1916  MULTIPOLYGON (((14.82540 55.25410, 14.94371 55...  \n",
       "1920  MULTIPOLYGON (((9.42015 54.83196, 9.42293 54.8...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUTS_shapefile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Austria': 'AT', 'Albania': 'AL', 'Belarus': 'BY', 'Belgium': 'BE', 'Bosnia and Herzegovina': 'BA', 'Bulgaria': 'BG', 'Croatia': 'HR', 'Czech Republic': 'CZ', 'Denmark': 'DK', 'Estonia': 'EE', 'Finland': 'FI', 'France': 'FR', 'Germany': 'DE', 'Greece': 'EL', 'Hungary': 'HU', 'Ireland': 'IE', 'Italy': 'IT', 'Kosovo': 'XK', 'Latvia': 'LV', 'Lithuania': 'LT', 'Luxembourg': 'LU', 'Macedonia': 'MK', 'Moldova': 'MD', 'Montenegro': 'ME', 'Netherlands': 'NL', 'Norway': 'NO', 'Poland': 'PL', 'Portugal': 'PT', 'Romania': 'RO', 'Serbia': 'RS', 'Slovakia': 'SK', 'Slovenia': 'SI', 'Spain': 'ES', 'Sweden': 'SE', 'Switzerland': 'CH', 'Turkey': 'TR', 'Ukraine': 'UA', 'United Kingdom': 'UK'}\n"
     ]
    }
   ],
   "source": [
    "# Restrict to only the countries with codes in the countries_nuts_id dictionarry\n",
    "print(dicts.countries_nuts_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the second element of the tuple\n",
    "countries_codes = list(dicts.countries_nuts_id.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit the gpd to the countries in the dictionary\n",
    "NUTS_shapefile = NUTS_shapefile[NUTS_shapefile.NUTS_ID.isin(countries_codes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NUTS_ID</th>\n",
       "      <th>LEVL_CODE</th>\n",
       "      <th>CNTR_CODE</th>\n",
       "      <th>NAME_LATN</th>\n",
       "      <th>NUTS_NAME</th>\n",
       "      <th>MOUNT_TYPE</th>\n",
       "      <th>URBN_TYPE</th>\n",
       "      <th>COAST_TYPE</th>\n",
       "      <th>FID</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1901</th>\n",
       "      <td>AL</td>\n",
       "      <td>0</td>\n",
       "      <td>AL</td>\n",
       "      <td>Shqipëria</td>\n",
       "      <td>Shqipëria</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>AL</td>\n",
       "      <td>POLYGON ((19.82698 42.46950, 19.83939 42.46950...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1902</th>\n",
       "      <td>AT</td>\n",
       "      <td>0</td>\n",
       "      <td>AT</td>\n",
       "      <td>Österreich</td>\n",
       "      <td>Österreich</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>AT</td>\n",
       "      <td>POLYGON ((15.54245 48.90770, 15.75363 48.85218...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1903</th>\n",
       "      <td>BE</td>\n",
       "      <td>0</td>\n",
       "      <td>BE</td>\n",
       "      <td>Belgique/België</td>\n",
       "      <td>Belgique/België</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BE</td>\n",
       "      <td>POLYGON ((5.10218 51.42900, 5.08780 51.38230, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1916</th>\n",
       "      <td>DK</td>\n",
       "      <td>0</td>\n",
       "      <td>DK</td>\n",
       "      <td>Danmark</td>\n",
       "      <td>Danmark</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>DK</td>\n",
       "      <td>MULTIPOLYGON (((14.82540 55.25410, 14.94371 55...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1920</th>\n",
       "      <td>DE</td>\n",
       "      <td>0</td>\n",
       "      <td>DE</td>\n",
       "      <td>Deutschland</td>\n",
       "      <td>Deutschland</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>DE</td>\n",
       "      <td>MULTIPOLYGON (((9.42015 54.83196, 9.42293 54.8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     NUTS_ID  LEVL_CODE CNTR_CODE        NAME_LATN        NUTS_NAME  \\\n",
       "1901      AL          0        AL        Shqipëria        Shqipëria   \n",
       "1902      AT          0        AT       Österreich       Österreich   \n",
       "1903      BE          0        BE  Belgique/België  Belgique/België   \n",
       "1916      DK          0        DK          Danmark          Danmark   \n",
       "1920      DE          0        DE      Deutschland      Deutschland   \n",
       "\n",
       "      MOUNT_TYPE  URBN_TYPE  COAST_TYPE FID  \\\n",
       "1901         0.0          0           0  AL   \n",
       "1902         0.0          0           0  AT   \n",
       "1903         0.0          0           0  BE   \n",
       "1916         0.0          0           0  DK   \n",
       "1920         0.0          0           0  DE   \n",
       "\n",
       "                                               geometry  \n",
       "1901  POLYGON ((19.82698 42.46950, 19.83939 42.46950...  \n",
       "1902  POLYGON ((15.54245 48.90770, 15.75363 48.85218...  \n",
       "1903  POLYGON ((5.10218 51.42900, 5.08780 51.38230, ...  \n",
       "1916  MULTIPOLYGON (((14.82540 55.25410, 14.94371 55...  \n",
       "1920  MULTIPOLYGON (((9.42015 54.83196, 9.42293 54.8...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUTS_shapefile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only the NUTS_ID, NUTS_NAME, and geometry columns\n",
    "NUTS_shapefile = NUTS_shapefile[[\"NUTS_ID\", \"NUTS_NAME\", \"geometry\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NUTS_ID</th>\n",
       "      <th>NUTS_NAME</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1901</th>\n",
       "      <td>AL</td>\n",
       "      <td>Shqipëria</td>\n",
       "      <td>POLYGON ((19.82698 42.46950, 19.83939 42.46950...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1902</th>\n",
       "      <td>AT</td>\n",
       "      <td>Österreich</td>\n",
       "      <td>POLYGON ((15.54245 48.90770, 15.75363 48.85218...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1903</th>\n",
       "      <td>BE</td>\n",
       "      <td>Belgique/België</td>\n",
       "      <td>POLYGON ((5.10218 51.42900, 5.08780 51.38230, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1916</th>\n",
       "      <td>DK</td>\n",
       "      <td>Danmark</td>\n",
       "      <td>MULTIPOLYGON (((14.82540 55.25410, 14.94371 55...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1920</th>\n",
       "      <td>DE</td>\n",
       "      <td>Deutschland</td>\n",
       "      <td>MULTIPOLYGON (((9.42015 54.83196, 9.42293 54.8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     NUTS_ID        NUTS_NAME  \\\n",
       "1901      AL        Shqipëria   \n",
       "1902      AT       Österreich   \n",
       "1903      BE  Belgique/België   \n",
       "1916      DK          Danmark   \n",
       "1920      DE      Deutschland   \n",
       "\n",
       "                                               geometry  \n",
       "1901  POLYGON ((19.82698 42.46950, 19.83939 42.46950...  \n",
       "1902  POLYGON ((15.54245 48.90770, 15.75363 48.85218...  \n",
       "1903  POLYGON ((5.10218 51.42900, 5.08780 51.38230, ...  \n",
       "1916  MULTIPOLYGON (((14.82540 55.25410, 14.94371 55...  \n",
       "1920  MULTIPOLYGON (((9.42015 54.83196, 9.42293 54.8...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUTS_shapefile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading model NAO data ###\n",
    "\n",
    "Loading the lagged and var adjusted NAO data from the .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file dire\n",
    "nao_df_dir = \"/gws/nopw/j04/canari/users/benhutch/nao_stats_df/\"\n",
    "nao_df_fname = \"psl_ONDJFM_global_1961_2014_2-9_4_nao_default.csv\"\n",
    "\n",
    "# Set up the model config\n",
    "model_config = {\n",
    "    \"variable\": \"psl\",\n",
    "    \"season\": \"ONDJFM\",\n",
    "    \"region\": \"global\",\n",
    "    \"start_year\": 1961,\n",
    "    \"end_year\": 2014,\n",
    "    \"forecast_range\": \"2-9\",\n",
    "    \"lag\": 4,\n",
    "    \"nao\": \"nao_default\",\n",
    "    \"gridbox\": \"North Europe Grid\",\n",
    "    \"method\": \"nao_matched\",\n",
    "}\n",
    "\n",
    "# # Load this in using pandas\n",
    "# nao_df = pd.read_csv(nao_df_dir + nao_df_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # view the head of the df\n",
    "# nao_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in the other NAO data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the data into chunks\n",
    "# ds_era5 = xr.open_mfdataset(\n",
    "#     dicts.regrid_file,\n",
    "#     combine=\"by_coords\",\n",
    "#     parallel=True,\n",
    "#     chunks={\"time\": \"auto\", \"latitude\": \"auto\", \"longitude\": \"auto\"},\n",
    "# )[\n",
    "#     \"msl\"\n",
    "# ]  # for mean sea level pressure\n",
    "\n",
    "# # Combine the first two expver variables\n",
    "# obs_msl = ds_era5.sel(expver=1).combine_first(ds_era5.sel(expver=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Constrain obs to ONDJFM\n",
    "# obs_msl = obs_msl.sel(time=obs_msl.time.dt.month.isin([10, 11, 12, 1, 2, 3]))\n",
    "\n",
    "# # Shift the time index back by 3 months\n",
    "# obs_msl_shifted = obs_msl.shift(time=-3)\n",
    "\n",
    "# # Take annual means\n",
    "# obs_msl_annual = obs_msl_shifted.resample(time=\"Y\").mean()\n",
    "\n",
    "# # Throw away years 1959, 2021, 2022 and 2023\n",
    "# obs_msl_annual = obs_msl_annual.sel(time=slice(\"1960\", \"2019\"))\n",
    "\n",
    "# # Remove the climatology\n",
    "# obs_msl_anomaly = obs_msl_annual - obs_msl_annual.mean(dim=\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extract the lats and lons of the azores\n",
    "# lat1, lat2 = dicts.azores_grid_corrected[\"lat1\"], dicts.azores_grid_corrected[\"lat2\"]\n",
    "# lon1, lon2 = dicts.azores_grid_corrected[\"lon1\"], dicts.azores_grid_corrected[\"lon2\"]\n",
    "\n",
    "# # Calculate the mean for the azores gridbox\n",
    "# obs_msl_anomaly_azores = obs_msl_anomaly.sel(\n",
    "#     lat=slice(lat1, lat2), lon=slice(lon1, lon2)\n",
    "# ).mean(dim=[\"lat\", \"lon\"])\n",
    "\n",
    "# # Same for iceland\n",
    "# lat1, lat2 = dicts.iceland_grid_corrected[\"lat1\"], dicts.iceland_grid_corrected[\"lat2\"]\n",
    "# lon1, lon2 = dicts.iceland_grid_corrected[\"lon1\"], dicts.iceland_grid_corrected[\"lon2\"]\n",
    "\n",
    "# # Calculate the mean for the iceland gridbox\n",
    "# obs_msl_anomaly_iceland = obs_msl_anomaly.sel(\n",
    "#     lat=slice(lat1, lat2), lon=slice(lon1, lon2)\n",
    "# ).mean(dim=[\"lat\", \"lon\"])\n",
    "\n",
    "# # Calculate the NAO index (azores - iceland)\n",
    "# nao_index = obs_msl_anomaly_azores - obs_msl_anomaly_iceland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # EXtract the time series\n",
    "# nao_index_time = nao_index.time.values\n",
    "\n",
    "# # Extract the values\n",
    "# nao_index_values = nao_index.values\n",
    "\n",
    "# # Create a dataframe\n",
    "# nao_running = pd.DataFrame({\"time\": nao_index_time, \"value\": nao_index_values})\n",
    "\n",
    "# # Take a centred 8-year running mean\n",
    "# nao_running = nao_running.set_index(\"time\").rolling(8, center=True).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nao_index_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Drop the Nans\n",
    "# nao_running = nao_running.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nao_running.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # split the time column into year and month\n",
    "# # split by - and take the first element\n",
    "# nao_running.index = nao_running.index.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nao_running.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # align the two dataframes by the index of time for nao_running\n",
    "# # and the valid time for nao_df\n",
    "# nao_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set the index of nao_df as the valid_time column\n",
    "# nao_df = nao_df.set_index(\"valid_time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nao_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # join the two dataframes\n",
    "# nao_df = nao_df.join(nao_running)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nao_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set the column with name 'value' to obs_nao_pd\n",
    "# nao_df = nao_df.rename(columns={\"value\": \"obs_nao_pd\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nao_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.stats import pearsonr\n",
    "\n",
    "# # Plot the obs_nao and obs_nao_pd, both divided by 100\n",
    "# # with valid_time (index) on the x-axis\n",
    "# plt.figure(figsize=(12, 8))\n",
    "\n",
    "# plt.plot(nao_df.index, nao_df[\"obs_nao\"] / 100, label=\"ERA5\", color=\"black\")\n",
    "\n",
    "# plt.plot(\n",
    "#     nao_df.index, nao_df[\"model_nao_mean\"] / 100, label=\"dcppA-hindcast\", color=\"blue\"\n",
    "# )\n",
    "\n",
    "# corr, p = pearsonr(nao_df[\"obs_nao\"], nao_df[\"model_nao_mean\"])\n",
    "\n",
    "# # Include a textbox in the top left hand corner with the corr and p values\n",
    "# plt.text(\n",
    "#     0.05,\n",
    "#     0.95,\n",
    "#     f\"Correlation: {round(corr, 2)}\\n p-value: {round(p, 2)}\",\n",
    "#     horizontalalignment=\"left\",\n",
    "#     verticalalignment=\"top\",\n",
    "#     transform=plt.gca().transAxes,\n",
    "#     bbox=dict(facecolor=\"white\", alpha=0.5),\n",
    "# )\n",
    "\n",
    "# plt.legend()\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to process the correlation data for the EEZ domains, then plot the strength of these correlations on the map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import the functions\n",
    "# import functions_em as funcs\n",
    "\n",
    "# # Extract the data from the .nc file\n",
    "# eez_cfs = funcs.extract_offshore_eez_to_df(\n",
    "#     filepath=os.path.join(dicts.clearheads_dir, \"EEZ_zones_wp_historical.nc\")\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Look at the head of the dataframe\n",
    "# eez_cfs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the functions\n",
    "import functions_em as funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'functions_em' from '/home/users/benhutch/energy-met-corr/functions_em.py'>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "\n",
    "importlib.reload(funcs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solar correlations ###\n",
    "\n",
    "Looking at correlations between climate indices (solar irradiance, NAO, delta P) and countrywide solar power generation from the CLEARHEADS data.\n",
    "\n",
    "The data we want is in:\n",
    "\n",
    "* *NUTS_0_sp_historical.nc* - Hourly area-averaged solar power capacity factors at NUTS0 level across Europe from 1950 to 2020.\n",
    "* *NUTS_0_sp_historical_loc_weighted.nc* - Hourly solar power capacity factors at NUTS0 level across Europe, from 01/01/1950 - 31/12/2020. Data is weighted by the location of known solar panels from Dunnett et al., (2020) and Stowell et al., (2020) for the UK.\n",
    "    * This dataset appears to be buggy, use the former."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ste up the model config\n",
    "# Set up the model config\n",
    "model_config = {\n",
    "    \"variable\": \"rsds\",\n",
    "    \"season\": \"ONDJFM\",\n",
    "    \"region\": \"global\",\n",
    "    \"start_year\": 1964,\n",
    "    \"end_year\": 2014,\n",
    "    \"forecast_range\": \"2-9\",\n",
    "    \"lag\": 4,\n",
    "    \"method\": \"alternate_lag\",\n",
    "}\n",
    "\n",
    "# Call the function\n",
    "dfs = funcs.correlate_nao_uread(\n",
    "    filename=\"NUTS_0_sp_historical.nc\",\n",
    "    shp_file=\"NUTS_RG_10M_2021_4326.shp\",\n",
    "    shp_file_dir=\"/home/users/benhutch/shapefiles/NUTS/\",\n",
    "    obs_var=\"ssrd\",\n",
    "    use_model_data=True,\n",
    "    model_config=model_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the data for obsserved correlations between\n",
    "# the NAO and solar power cpacity factors at NUTS0 levels\n",
    "# -- Not location weighted in this case --\n",
    "dfs = funcs.correlate_nao_uread(\n",
    "    filename=\"NUTS_0_sp_historical.nc\",\n",
    "    shp_file=\"\",\n",
    "    shp_file_dir=\"\",\n",
    "    obs_var=\"ssrd\",\n",
    "    use_model_data=True,\n",
    "    model_config=model_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(dfs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dfs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1, df2 = dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corr all NaNs - why?\n",
    "corr_df = df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nao_df_dir = \"/gws/nopw/j04/canari/users/benhutch/nao_stats_df/\"\n",
    "nao_df_fname = \"psl_ONDJFM_global_1961_2014_2-9_4_nao_default.csv\"\n",
    "\n",
    "# # Set up the model config\n",
    "# model_config = {\n",
    "#     \"variable\": \"psl\",\n",
    "#     \"season\": \"ONDJFM\",\n",
    "#     \"region\": \"global\",\n",
    "#     \"start_year\": 1961,\n",
    "#     \"end_year\": 2014,\n",
    "#     \"forecast_range\": \"2-9\",\n",
    "#     \"lag\": 4,\n",
    "#     \"nao\": \"thornton_2019_uk\",\n",
    "# }\n",
    "\n",
    "# Set up the model config\n",
    "model_config = {\n",
    "    \"variable\": \"psl\",\n",
    "    \"season\": \"ONDJFM\",\n",
    "    \"region\": \"global\",\n",
    "    \"start_year\": 1961,\n",
    "    \"end_year\": 2014,\n",
    "    \"forecast_range\": \"2-9\",\n",
    "    \"lag\": 4,\n",
    "    \"nao\": \"thornton_2019_uk\",\n",
    "    \"gridbox\": \"Scandinavia\",\n",
    "    \"method\": \"nao_matched\",\n",
    "}\n",
    "\n",
    "\n",
    "# EEZ_zones_wp_historical.nc\n",
    "# NUTS_0_HDD_historical_pop_weighted.nc\n",
    "# test the other function for doing this\n",
    "# days for cooling degree days\n",
    "df, merged_df, merged_df_full, corr_df = funcs.correlate_nao_uread(\n",
    "    filename=\"NUTS_0_HDD_historical_pop_weighted.nc\",\n",
    "    time_unit=\"d\",\n",
    "    obs_var=\"msl\",\n",
    "    avg_grid=dicts.scandi_box,\n",
    "    use_model_data=True,\n",
    "    model_config=model_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = funcs.calc_model_nao_gridbox_var_corr(\n",
    "    nao_df=merged_df,\n",
    "    gridbox=dicts.scandi_box,\n",
    "    obs_var=\"var228\",\n",
    "    obs_var_data_path=dicts.regrid_file_pr,\n",
    "    coeff_fname=\"delta_p_pr_scandi_slope.csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the plotting function\n",
    "funcs.plot_calib_corr(\n",
    "    df=df,\n",
    "    obs_var=\"var228\",\n",
    "    index_name=\"Calibrated delta P\",\n",
    "    ylabel=\"Scandi precip anoms. (mm/day)\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the calibrated_model_nao_mean against the var228 anomaly mean\n",
    "# with seperate y-axes\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Create a new figure and an axes\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "# Plot the calibrated_model_nao_mean on the first y-axis\n",
    "ax1.plot(df.index, df[\"calibrated_model_nao_mean\"], color=\"blue\", label=\"nao\")\n",
    "ax1.set_ylabel(\"pr anomalies (mm/day)\")\n",
    "# Plot the var228 anomaly mean on the second y-axis\n",
    "ax1.plot(df.index, df[\"var228 anomaly mean\"], color=\"red\", label=\"var228\")\n",
    "\n",
    "# show the correlation coefiients\n",
    "corr, p = pearsonr(df[\"calibrated_model_nao_mean\"], df[\"var228 anomaly mean\"])\n",
    "\n",
    "# Include a textbox in the top left hand corner with the corr and p values\n",
    "plt.text(\n",
    "    0.05,\n",
    "    0.95,\n",
    "    f\"Corr: {round(corr, 2)}\\n p-value: {round(p, 2)}\",\n",
    "    horizontalalignment=\"left\",\n",
    "    verticalalignment=\"top\",\n",
    "    transform=plt.gca().transAxes,\n",
    "    bbox=dict(facecolor=\"white\", alpha=0.5),\n",
    ")\n",
    "\n",
    "# Include a horixzontal black dashed line at y=0\n",
    "plt.axhline(0, color=\"black\", linestyle=\"--\")\n",
    "\n",
    "# Include a legend\n",
    "plt.legend(loc=\"upper right\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{p:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the NUTS shapefiles\n",
    "# Load in the shapefile fo the eez data\n",
    "NUTS_shapefile = gpd.read_file(\"~/shapefiles/NUTS/NUTS_RG_10M_2021_4326.shp\")\n",
    "\n",
    "# Restrict to level code 0\n",
    "NUTS_shapefile = NUTS_shapefile[NUTS_shapefile.LEVL_CODE == 0]\n",
    "\n",
    "# Extract the second element of the tuple\n",
    "countries_codes = list(dicts.countries_nuts_id.values())\n",
    "\n",
    "# Limit the gpd to the countries in the dictionary\n",
    "NUTS_shapefile = NUTS_shapefile[NUTS_shapefile.NUTS_ID.isin(countries_codes)]\n",
    "\n",
    "# Keep only the NUTS_ID, NUTS_NAME, and geometry columns\n",
    "NUTS_shapefile = NUTS_shapefile[[\"NUTS_ID\", \"NUTS_NAME\", \"geometry\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUTS_shapefile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the shapefile fo the eez data\n",
    "EEZ_shapefile = gpd.read_file(\"shapefiles/EEZ/eez_v12.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EEZ_shapefile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print all of the column names for the eeZ shapefile\n",
    "print(EEZ_shapefile.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Throw away all of the columns, apart from \"GEONAME\", 'SOVEREIGN1',\n",
    "# \"ISOSOV1\", \"geometry\"\n",
    "EEZ_shapefile = EEZ_shapefile[[\"GEONAME\", \"SOVEREIGN1\", \"ISO_SOV1\", \"geometry\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EEZ_shapefile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iso_sov1 = EEZ_shapefile[\"ISO_SOV1\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iso_sov1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the values of the region column from corr_df\n",
    "region_values = corr_df.region.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload the dictionary\n",
    "importlib.reload(dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the region values to equivalent iso_sov1 values\n",
    "# using the mapping in the dictionary\n",
    "iso_sov1_values = [dicts.iso_mapping[region] for region in region_values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iso_sov1_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constrain the geo dataframe to only include the iso_sov1 values\n",
    "EEZ_shapefile = EEZ_shapefile[EEZ_shapefile[\"ISO_SOV1\"].isin(iso_sov1_values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find where ISO_SOV1 is equal to \"ITA\"\n",
    "EEZ_shapefile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where corr_df.region passed through iso_mapping dict is\n",
    "# equal to the values in EEZ_shapefile.ISO_SOV1\n",
    "# Add the corresponding correlation and p-value to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter df to only include the rows where GEONAME includes: \"Exclusive Economic Zone\"\n",
    "EEZ_shapefile = EEZ_shapefile[\n",
    "    EEZ_shapefile[\"GEONAME\"].str.contains(\"Exclusive Economic Zone\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EEZ_shapefile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we want to append the correlation and p-value to the dataframe\n",
    "# Add a new column to corr_df called \"ISO_SOV1\"\n",
    "corr_df[\"ISO_SOV1\"] = iso_sov1_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df[\"region\"] == \"EL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over the columns in EEZ_shapefile and add the correlation and p-value\n",
    "# where the ISO_SOV1 values are equal\n",
    "for index, row in EEZ_shapefile.iterrows():\n",
    "    # Extract the ISO_SOV1 value\n",
    "    iso_sov1 = row[\"ISO_SOV1\"]\n",
    "    # Find the index of the row in corr_df that matches the ISO_SOV1\n",
    "    index_corr = corr_df[corr_df[\"ISO_SOV1\"] == iso_sov1].index\n",
    "    # Add the correlation and p-value to the dataframe\n",
    "    EEZ_shapefile.loc[index, \"correlation\"] = corr_df.loc[\n",
    "        index_corr, \"correlation\"\n",
    "    ].values\n",
    "    EEZ_shapefile.loc[index, \"p-value\"] = corr_df.loc[index_corr, \"p-value\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same thing for the NUTS_shapefile\n",
    "for index, row in NUTS_shapefile.iterrows():\n",
    "    # Extract the NUTS_ID value\n",
    "    nuts_id = row[\"NUTS_ID\"]\n",
    "\n",
    "    # Find the index of the row in corr_df that matches the NUTS_ID\n",
    "    index_corr = corr_df[corr_df[\"region\"] == nuts_id].index\n",
    "\n",
    "    if len(index_corr) == 0:\n",
    "        print(f\"No match found for {nuts_id}\")\n",
    "        continue\n",
    "\n",
    "    # Add the correlation and p-value to the dataframe\n",
    "    NUTS_shapefile.loc[index, \"correlation\"] = corr_df.loc[\n",
    "        index_corr, \"correlation\"\n",
    "    ].values\n",
    "\n",
    "    NUTS_shapefile.loc[index, \"p-value\"] = corr_df.loc[index_corr, \"p-value\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EEZ_shapefile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUTS_shapefile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any rows from EEZ shapefile which contain \"(*)\" in the GEONAME column\n",
    "EEZ_shapefile = EEZ_shapefile[~EEZ_shapefile[\"GEONAME\"].str.contains(r\"\\(.*\\)\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EEZ_shapefile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(EEZ_shapefile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the dicts\n",
    "importlib.reload(dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "# Now plot the EEZ_shapefile with the correlation as the color\n",
    "plt.figure(figsize=(10, 10))\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "NUTS_shapefile.plot(\n",
    "    column=\"correlation\",\n",
    "    ax=ax,\n",
    "    legend=True,\n",
    "    cmap=\"coolwarm\",\n",
    "    vmin=-1,\n",
    "    vmax=1,\n",
    "    legend_kwds={\n",
    "        \"label\": \"Correlation\",\n",
    "        \"orientation\": \"horizontal\",\n",
    "        \"shrink\": 0.8,\n",
    "        \"pad\": 0.01,\n",
    "    },\n",
    ")\n",
    "# Use cartopy to add the coastlines\n",
    "ax.coastlines()\n",
    "# Make the colorbar smaller\n",
    "cbar = ax.get_figure().get_axes()[1]\n",
    "cbar.set_ylabel(\"Correlation\", fontsize=12)\n",
    "cbar.tick_params(labelsize=10)\n",
    "\n",
    "# Extract the lats of the northern eu grid box\n",
    "lat1, lat2 = dicts.med_box_focus[\"lat1\"], dicts.med_box_focus[\"lat2\"]\n",
    "lon1, lon2 = dicts.med_box_focus[\"lon1\"], dicts.med_box_focus[\"lon2\"]\n",
    "\n",
    "# Plot the grid box\n",
    "plt.plot([lon1, lon2, lon2, lon1, lon1], [lat1, lat1, lat2, lat2, lat1], \"r\")\n",
    "\n",
    "# Include hazels grid box\n",
    "lat1_n, lat2_n = (\n",
    "    dicts.uk_n_box_corrected[\"lat1\"],\n",
    "    dicts.uk_n_box_corrected[\"lat2\"],\n",
    ")\n",
    "lon1_n, lon2_n = (\n",
    "    dicts.uk_n_box_corrected[\"lon1\"],\n",
    "    dicts.uk_n_box_corrected[\"lon2\"],\n",
    ")\n",
    "\n",
    "# Plot the grid box\n",
    "# plt.plot(\n",
    "#     [lon1_n, lon2_n, lon2_n, lon1_n, lon1_n],\n",
    "#     [lat1_n, lat1_n, lat2_n, lat2_n, lat1_n],\n",
    "#     \"g\",\n",
    "# )\n",
    "\n",
    "# Include hazels grid box\n",
    "lat1_s, lat2_s = (\n",
    "    dicts.uk_s_box_corrected[\"lat1\"],\n",
    "    dicts.uk_s_box_corrected[\"lat2\"],\n",
    ")\n",
    "lon1_s, lon2_s = (\n",
    "    dicts.uk_s_box_corrected[\"lon1\"],\n",
    "    dicts.uk_s_box_corrected[\"lon2\"],\n",
    ")\n",
    "\n",
    "# Plot the grid box\n",
    "# plt.plot(\n",
    "#     [lon1_s, lon2_s, lon2_s, lon1_s, lon1_s],\n",
    "#     [lat1_s, lat1_s, lat2_s, lat2_s, lat1_s],\n",
    "#     \"g\",\n",
    "# )\n",
    "\n",
    "# Include ticks for the lat and lon\n",
    "ax.gridlines(draw_labels=True)\n",
    "\n",
    "# Constrain to specific bounds\n",
    "ax.set_xlim(-40, 50)\n",
    "ax.set_ylim(30, 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the dictionary\n",
    "importlib.reload(dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit the EEZ_shapefile to only include only the ISO_SOV1 values\n",
    "# Which are in dicts.eez_agg_countries\n",
    "EEZ_shapefile_n = EEZ_shapefile[EEZ_shapefile[\"ISO_SOV1\"].isin(dicts.eez_agg_countries)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now plot the EEZ_shapefile with the correlation as the color\n",
    "plt.figure(figsize=(10, 10))\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "EEZ_shapefile_n.plot(\n",
    "    column=\"correlation\",\n",
    "    ax=ax,\n",
    "    legend=True,\n",
    "    cmap=\"coolwarm\",\n",
    "    vmin=-1,\n",
    "    vmax=1,\n",
    "    legend_kwds={\n",
    "        \"label\": \"Correlation\",\n",
    "        \"orientation\": \"horizontal\",\n",
    "        \"shrink\": 0.8,\n",
    "        \"pad\": 0.01,\n",
    "    },\n",
    ")\n",
    "# Use cartopy to add the coastlines\n",
    "ax.coastlines()\n",
    "# Make the colorbar smaller\n",
    "cbar = ax.get_figure().get_axes()[1]\n",
    "cbar.set_ylabel(\"Correlation\", fontsize=12)\n",
    "cbar.tick_params(labelsize=10)\n",
    "\n",
    "# Include ticks for the lat and lon\n",
    "ax.gridlines(draw_labels=True)\n",
    "\n",
    "# Constrain to specific bounds\n",
    "ax.set_xlim(-40, 50)\n",
    "ax.set_ylim(30, 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload dicts\n",
    "importlib.reload(dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column in cfs called N_Europe\n",
    "# which is the average of all of the countries (columns) in dicts.eez_agg_countries\n",
    "# Convert to three character names first\n",
    "for key in dicts.iso_mapping:\n",
    "    merged_df = merged_df.rename(columns={key: dicts.iso_mapping[key]})\n",
    "\n",
    "merged_df[\"N_Europe\"] = merged_df[dicts.eez_agg_countries].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Create a plot with two y-axes\n",
    "# Time on the x-axes\n",
    "# The variable on the left y-axes is the NAO anomaly (Pa)\n",
    "# The variable on the right y-axes is the wind power (GW) for N_Europe\n",
    "fig, ax1 = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "# Plot the NAO anomaly\n",
    "ax1.plot(merged_df.index, merged_df[\"ssrd anomaly mean\"], \"b-\")\n",
    "\n",
    "# Set the x-axis label\n",
    "ax1.set_xlabel(\"Time\")\n",
    "\n",
    "# Set the y-axis label\n",
    "ax1.set_ylabel(\"Obs solar irradiance (W/m^2)\", color=\"b\")\n",
    "\n",
    "# Include a black dashed line for y=0\n",
    "ax1.axhline(0, color=\"black\", linestyle=\"--\")\n",
    "\n",
    "# Set the color of the ticks\n",
    "ax1.tick_params(\"y\", colors=\"b\")\n",
    "\n",
    "# Create a second y-axis\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "# Plot the wind power\n",
    "ax2.plot(merged_df.index, merged_df.ES, \"r-\")\n",
    "\n",
    "# Set the y-axis label\n",
    "ax2.set_ylabel(\"Spain solar CFs (GW)\", color=\"r\")\n",
    "\n",
    "# Set the colour of the ticks\n",
    "ax2.tick_params(\"y\", colors=\"r\")\n",
    "\n",
    "# # Invert the y-axis\n",
    "# ax2.invert_yaxis()\n",
    "\n",
    "# Calculate the correlation between the NAO anomaly and the wind power\n",
    "corr, p = pearsonr(merged_df[\"ssrd anomaly mean\"], merged_df.ES)\n",
    "\n",
    "# Include the correlation and p-value on the plot\n",
    "ax2.text(\n",
    "    0.05,\n",
    "    0.95,\n",
    "    f\"Correlation: {corr:.2f}\\nP-value: {p:.2f}\",\n",
    "    horizontalalignment=\"left\",\n",
    "    verticalalignment=\"top\",\n",
    "    bbox=dict(facecolor=\"white\", alpha=0.5),\n",
    "    transform=ax2.transAxes,\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a scatter plot of NAO agaist wind power\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "# Plot the scatter plot\n",
    "plt.scatter(merged_df[\"fcst_ts_mean\"], merged_df.N_Europe, color=\"k\")\n",
    "\n",
    "# Include a line of best fit\n",
    "m, b = np.polyfit(merged_df[\"fcst_ts_mean\"], merged_df.N_Europe, 1)\n",
    "\n",
    "# Plot the line of best fit\n",
    "plt.plot(\n",
    "    merged_df[\"fcst_ts_mean\"],\n",
    "    m * merged_df[\"fcst_ts_mean\"] + b,\n",
    "    \"k\",\n",
    ")\n",
    "\n",
    "# Set the x-axis label\n",
    "plt.xlabel(\"Model wind speed anomalies (m/s))\", color=\"b\")\n",
    "\n",
    "# Set the xticks to blue\n",
    "plt.tick_params(axis=\"x\", colors=\"b\")\n",
    "\n",
    "# Set the y-axis label\n",
    "plt.ylabel(\"Obs Wind Power (GW)\", color=\"r\")\n",
    "\n",
    "# Set the yticks to red\n",
    "plt.tick_params(axis=\"y\", colors=\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the ERA5 data for the NAO index\n",
    "# Use this file\n",
    "# adaptor.mars.internal-1691509121.3261805-29348-4-3a487c76-fc7b-421f-b5be-7436e2eb78d7.nc\n",
    "# in ~/ERA5/\n",
    "# Load the dataset\n",
    "era5_data_path = \"~/ERA5/adaptor.mars.internal-1691509121.3261805-29348-4-3a487c76-fc7b-421f-b5be-7436e2eb78d7.nc\"\n",
    "\n",
    "# Load the data into chunks\n",
    "ds_era5 = xr.open_mfdataset(\n",
    "    era5_data_path,\n",
    "    combine=\"by_coords\",\n",
    "    parallel=True,\n",
    "    chunks={\"time\": 100, \"latitude\": 100, \"longitude\": 100},\n",
    ")[\n",
    "    \"msl\"\n",
    "]  # for mean sea level pressure\n",
    "\n",
    "# Combine the first two expver variables\n",
    "obs_msl = ds_era5.sel(expver=1).combine_first(ds_era5.sel(expver=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constrain obs to ONDJFM\n",
    "obs_msl = obs_msl.sel(time=obs_msl.time.dt.month.isin([10, 11, 12, 1, 2, 3]))\n",
    "\n",
    "# Shift the time index back by 3 months\n",
    "obs_msl_shifted = obs_msl.shift(time=-3)\n",
    "\n",
    "# Take annual means\n",
    "obs_msl_annual = obs_msl_shifted.resample(time=\"Y\").mean()\n",
    "\n",
    "# Throw away years 1959, 2021, 2022 and 2023\n",
    "obs_msl_annual = obs_msl_annual.sel(time=slice(\"1960\", \"2019\"))\n",
    "\n",
    "# Remove the climatology\n",
    "obs_msl_anomaly = obs_msl_annual - obs_msl_annual.mean(dim=\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the lats and lons of the azores\n",
    "lat1, lat2 = dicts.era5_azores[\"lat1\"], dicts.era5_azores[\"lat2\"]\n",
    "lon1, lon2 = dicts.era5_azores[\"lon1\"], dicts.era5_azores[\"lon2\"]\n",
    "\n",
    "# Calculate the mean for the azores gridbox\n",
    "obs_msl_anomaly_azores = obs_msl_anomaly.sel(\n",
    "    latitude=slice(lat1, lat2), longitude=slice(lon1, lon2)\n",
    ").mean(dim=[\"latitude\", \"longitude\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same for iceland\n",
    "lat1, lat2 = dicts.era5_iceland[\"lat1\"], dicts.era5_iceland[\"lat2\"]\n",
    "lon1, lon2 = dicts.era5_iceland[\"lon1\"], dicts.era5_iceland[\"lon2\"]\n",
    "\n",
    "# Calculate the mean for the iceland gridbox\n",
    "obs_msl_anomaly_iceland = obs_msl_anomaly.sel(\n",
    "    latitude=slice(lat1, lat2), longitude=slice(lon1, lon2)\n",
    ").mean(dim=[\"latitude\", \"longitude\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the NAO index (azores - iceland)\n",
    "nao_index = obs_msl_anomaly_azores - obs_msl_anomaly_iceland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXtract the time series\n",
    "nao_index_time = nao_index.time.values\n",
    "\n",
    "# Extract the values\n",
    "nao_index_values = nao_index.values\n",
    "\n",
    "# Create a dataframe\n",
    "nao_df = pd.DataFrame({\"time\": nao_index_time, \"value\": nao_index_values})\n",
    "\n",
    "# Take a centred 8-year running mean\n",
    "nao_running = nao_df.set_index(\"time\").rolling(8, center=True).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have a look at the dataframe\n",
    "nao_running.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the NaN values\n",
    "nao_running = nao_running.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the two dataframes into one, using the index of the first\n",
    "eez_df = eez_cfs.join(nao_running, how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eez_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the value column as 'NAO anomaly (Pa)'\n",
    "eez_df = eez_df.rename(columns={\"value\": \"NAO anomaly (Pa)\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the rows which contain NaN values in the NAO anomaly column\n",
    "eez_df = eez_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eez_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "import pandas as pd\n",
    "\n",
    "# Create a new dataframe with columns for:\n",
    "# 'region' - e.g. Netherlands_7\n",
    "# 'correlation' - the correlation between the NAO and the offshore wind CFs\n",
    "# 'p-value' - the p-value of the correlation\n",
    "# Set up the dataframe\n",
    "correlation_df = pd.DataFrame(columns=[\"region\", \"correlation\", \"p-value\"])\n",
    "\n",
    "# Loop over the regions\n",
    "for region in eez_df.columns[:-1]:\n",
    "    # Calculate the correlation\n",
    "    corr, p = pearsonr(eez_df[region], eez_df[\"NAO anomaly (Pa)\"])\n",
    "\n",
    "    # Create a new DataFrame to append\n",
    "    df_to_append = pd.DataFrame(\n",
    "        {\"region\": [region], \"correlation\": [corr], \"p-value\": [p]}\n",
    "    )\n",
    "\n",
    "    # Append to the dataframe\n",
    "    correlation_df = pd.concat([correlation_df, df_to_append], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the numbers from the region column by removing the last 2 characters\n",
    "correlation_df[\"region\"] = correlation_df[\"region\"].str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if any of the region names contain the string \"_\" then remove it\n",
    "correlation_df[\"region\"] = correlation_df[\"region\"].str.replace(\"_\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EEZ_shapefile[\"SOVEREIGN1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two new columns in the geopandas dataframe 'EEZ_shapefile'\n",
    "# 'correlation' - the correlation between the NAO and the offshore wind CFs\n",
    "# 'p-value' - the p-value of the correlation\n",
    "EEZ_shapefile[\"correlation\"] = np.nan\n",
    "EEZ_shapefile[\"p-value\"] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EEZ_shapefile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over the regions in correlation_df\n",
    "for region in correlation_df[\"region\"]:\n",
    "    # Extract the row from correlation_df\n",
    "    row = correlation_df[correlation_df[\"region\"] == region]\n",
    "\n",
    "    # Extract the correlation and p-value\n",
    "    corr = row[\"correlation\"].values[0]\n",
    "    p = row[\"p-value\"].values[0]\n",
    "\n",
    "    # Set the values in the EEZ_shapefile\n",
    "    EEZ_shapefile.loc[EEZ_shapefile[\"TERRITORY1\"] == region, \"correlation\"] = corr\n",
    "    EEZ_shapefile.loc[EEZ_shapefile[\"TERRITORY1\"] == region, \"p-value\"] = p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EEZ_shapefile[\"TERRITORY1\"] == \"France\", \"correlation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the list of Terrirories\n",
    "territories = EEZ_shapefile[\"TERRITORY1\"]\n",
    "\n",
    "# Convert to a list\n",
    "territories = list(territories)\n",
    "\n",
    "# Print the territories\n",
    "print(territories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constrain EEZ shapefile to only include the territories in the list\n",
    "EEZ_shapefile = EEZ_shapefile[EEZ_shapefile[\"TERRITORY1\"].isin(dicts.countries_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the correlation values for FRance\n",
    "print(EEZ_shapefile[EEZ_shapefile[\"SOVEREIGN1\"] == \"France\"][\"correlation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "# Now plot the EEZ_shapefile with the correlation as the color\n",
    "plt.figure(figsize=(10, 10))\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "EEZ_shapefile.plot(\n",
    "    column=\"correlation\", ax=ax, legend=True, cmap=\"coolwarm\", shrink=0.5\n",
    ")\n",
    "# Use cartopy to add the coastlines\n",
    "ax.coastlines()\n",
    "# Make the colorbar smaller\n",
    "cbar = ax.get_figure().get_axes()[1]\n",
    "cbar.set_ylabel(\"Correlation\", fontsize=12)\n",
    "cbar.tick_params(labelsize=10)\n",
    "\n",
    "# Constrain to specific bounds\n",
    "ax.set_xlim(-50, 50)\n",
    "ax.set_ylim(30, 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now plot the EEZ_shapefile with the correlation as the color\n",
    "fig, ax = plt.subplots(figsize=(10, 10), subplot_kw={\"projection\": ccrs.PlateCarree()})\n",
    "cax = EEZ_shapefile.plot(\n",
    "    column=\"correlation\", ax=ax, cmap=\"coolwarm\", add_colorbar=False\n",
    ")\n",
    "\n",
    "# Use cartopy to add the coastlines\n",
    "ax.coastlines()\n",
    "\n",
    "# Add colorbar\n",
    "cbar = fig.colorbar(cax.collections[0], ax=ax, shrink=0.5)\n",
    "cbar.set_label(\"Correlation\")\n",
    "\n",
    "# Constrain to specific bounds\n",
    "ax.set_xlim(-50, 50)\n",
    "ax.set_ylim(30, 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bens-python-environment",
   "language": "python",
   "name": "bens-python-environment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
