{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the relevant modules\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "\n",
    "# Import third party modules\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dictionaries_em as dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Testing the NUTS shapefiles\n",
    "# # Load in the shapefile fo the eez data\n",
    "# NUTS_shapefile = gpd.read_file(\"~/shapefiles/NUTS/NUTS_RG_10M_2021_4326.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NUTS_shapefile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Restrict to level code 0\n",
    "# NUTS_shapefile = NUTS_shapefile[NUTS_shapefile.LEVL_CODE == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NUTS_shapefile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Restrict to only the countries with codes in the countries_nuts_id dictionarry\n",
    "# print(dicts.countries_nuts_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the second element of the tuple\n",
    "# countries_codes = list(dicts.countries_nuts_id.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit the gpd to the countries in the dictionary\n",
    "# NUTS_shapefile = NUTS_shapefile[NUTS_shapefile.NUTS_ID.isin(countries_codes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NUTS_shapefile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Keep only the NUTS_ID, NUTS_NAME, and geometry columns\n",
    "# NUTS_shapefile = NUTS_shapefile[[\"NUTS_ID\", \"NUTS_NAME\", \"geometry\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NUTS_shapefile.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading model NAO data ###\n",
    "\n",
    "Loading the lagged and var adjusted NAO data from the .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the file dire\n",
    "# nao_df_dir = \"/gws/nopw/j04/canari/users/benhutch/nao_stats_df/\"\n",
    "# nao_df_fname = \"psl_ONDJFM_global_1961_2014_2-9_4_nao_default.csv\"\n",
    "\n",
    "# # Set up the model config\n",
    "# model_config = {\n",
    "#     \"variable\": \"psl\",\n",
    "#     \"season\": \"ONDJFM\",\n",
    "#     \"region\": \"global\",\n",
    "#     \"start_year\": 1961,\n",
    "#     \"end_year\": 2014,\n",
    "#     \"forecast_range\": \"2-9\",\n",
    "#     \"lag\": 4,\n",
    "#     \"nao\": \"nao_default\",\n",
    "#     \"gridbox\": \"North Europe Grid\",\n",
    "#     \"method\": \"nao_matched\",\n",
    "# }\n",
    "\n",
    "# # # Load this in using pandas\n",
    "# # nao_df = pd.read_csv(nao_df_dir + nao_df_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # view the head of the df\n",
    "# nao_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in the other NAO data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the data into chunks\n",
    "# ds_era5 = xr.open_mfdataset(\n",
    "#     dicts.regrid_file,\n",
    "#     combine=\"by_coords\",\n",
    "#     parallel=True,\n",
    "#     chunks={\"time\": \"auto\", \"latitude\": \"auto\", \"longitude\": \"auto\"},\n",
    "# )[\n",
    "#     \"msl\"\n",
    "# ]  # for mean sea level pressure\n",
    "\n",
    "# # Combine the first two expver variables\n",
    "# obs_msl = ds_era5.sel(expver=1).combine_first(ds_era5.sel(expver=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Constrain obs to ONDJFM\n",
    "# obs_msl = obs_msl.sel(time=obs_msl.time.dt.month.isin([10, 11, 12, 1, 2, 3]))\n",
    "\n",
    "# # Shift the time index back by 3 months\n",
    "# obs_msl_shifted = obs_msl.shift(time=-3)\n",
    "\n",
    "# # Take annual means\n",
    "# obs_msl_annual = obs_msl_shifted.resample(time=\"Y\").mean()\n",
    "\n",
    "# # Throw away years 1959, 2021, 2022 and 2023\n",
    "# obs_msl_annual = obs_msl_annual.sel(time=slice(\"1960\", \"2019\"))\n",
    "\n",
    "# # Remove the climatology\n",
    "# obs_msl_anomaly = obs_msl_annual - obs_msl_annual.mean(dim=\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extract the lats and lons of the azores\n",
    "# lat1, lat2 = dicts.azores_grid_corrected[\"lat1\"], dicts.azores_grid_corrected[\"lat2\"]\n",
    "# lon1, lon2 = dicts.azores_grid_corrected[\"lon1\"], dicts.azores_grid_corrected[\"lon2\"]\n",
    "\n",
    "# # Calculate the mean for the azores gridbox\n",
    "# obs_msl_anomaly_azores = obs_msl_anomaly.sel(\n",
    "#     lat=slice(lat1, lat2), lon=slice(lon1, lon2)\n",
    "# ).mean(dim=[\"lat\", \"lon\"])\n",
    "\n",
    "# # Same for iceland\n",
    "# lat1, lat2 = dicts.iceland_grid_corrected[\"lat1\"], dicts.iceland_grid_corrected[\"lat2\"]\n",
    "# lon1, lon2 = dicts.iceland_grid_corrected[\"lon1\"], dicts.iceland_grid_corrected[\"lon2\"]\n",
    "\n",
    "# # Calculate the mean for the iceland gridbox\n",
    "# obs_msl_anomaly_iceland = obs_msl_anomaly.sel(\n",
    "#     lat=slice(lat1, lat2), lon=slice(lon1, lon2)\n",
    "# ).mean(dim=[\"lat\", \"lon\"])\n",
    "\n",
    "# # Calculate the NAO index (azores - iceland)\n",
    "# nao_index = obs_msl_anomaly_azores - obs_msl_anomaly_iceland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # EXtract the time series\n",
    "# nao_index_time = nao_index.time.values\n",
    "\n",
    "# # Extract the values\n",
    "# nao_index_values = nao_index.values\n",
    "\n",
    "# # Create a dataframe\n",
    "# nao_running = pd.DataFrame({\"time\": nao_index_time, \"value\": nao_index_values})\n",
    "\n",
    "# # Take a centred 8-year running mean\n",
    "# nao_running = nao_running.set_index(\"time\").rolling(8, center=True).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nao_index_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Drop the Nans\n",
    "# nao_running = nao_running.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nao_running.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # split the time column into year and month\n",
    "# # split by - and take the first element\n",
    "# nao_running.index = nao_running.index.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nao_running.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # align the two dataframes by the index of time for nao_running\n",
    "# # and the valid time for nao_df\n",
    "# nao_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set the index of nao_df as the valid_time column\n",
    "# nao_df = nao_df.set_index(\"valid_time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nao_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # join the two dataframes\n",
    "# nao_df = nao_df.join(nao_running)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nao_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set the column with name 'value' to obs_nao_pd\n",
    "# nao_df = nao_df.rename(columns={\"value\": \"obs_nao_pd\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nao_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.stats import pearsonr\n",
    "\n",
    "# # Plot the obs_nao and obs_nao_pd, both divided by 100\n",
    "# # with valid_time (index) on the x-axis\n",
    "# plt.figure(figsize=(12, 8))\n",
    "\n",
    "# plt.plot(nao_df.index, nao_df[\"obs_nao\"] / 100, label=\"ERA5\", color=\"black\")\n",
    "\n",
    "# plt.plot(\n",
    "#     nao_df.index, nao_df[\"model_nao_mean\"] / 100, label=\"dcppA-hindcast\", color=\"blue\"\n",
    "# )\n",
    "\n",
    "# corr, p = pearsonr(nao_df[\"obs_nao\"], nao_df[\"model_nao_mean\"])\n",
    "\n",
    "# # Include a textbox in the top left hand corner with the corr and p values\n",
    "# plt.text(\n",
    "#     0.05,\n",
    "#     0.95,\n",
    "#     f\"Correlation: {round(corr, 2)}\\n p-value: {round(p, 2)}\",\n",
    "#     horizontalalignment=\"left\",\n",
    "#     verticalalignment=\"top\",\n",
    "#     transform=plt.gca().transAxes,\n",
    "#     bbox=dict(facecolor=\"white\", alpha=0.5),\n",
    "# )\n",
    "\n",
    "# plt.legend()\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to process the correlation data for the EEZ domains, then plot the strength of these correlations on the map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import the functions\n",
    "# import functions_em as funcs\n",
    "\n",
    "# # Extract the data from the .nc file\n",
    "# eez_cfs = funcs.extract_offshore_eez_to_df(\n",
    "#     filepath=os.path.join(dicts.clearheads_dir, \"EEZ_zones_wp_historical.nc\")\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Look at the head of the dataframe\n",
    "# eez_cfs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"/home/users/benhutch/energy-met-corr-functions\")\n",
    "\n",
    "# Import the functions\n",
    "import functions_em as funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "importlib.reload(funcs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate onshore wind correlations ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_vars = [\"si10\", \"var131\"]\n",
    "obs_var_data_paths = [dicts.regrid_file, dicts.obs_u_850_regrid]\n",
    "obs_var_levels = [0, 85000]\n",
    "\n",
    "# set up the model dict for si10\n",
    "# model config for 10m wind speeds\n",
    "model_config_sfcWind = {\n",
    "    \"variable\": \"sfcWind\",\n",
    "    \"season\": \"ONDJFM\",\n",
    "    \"region\": \"global\",\n",
    "    \"nao\": \"nao_default\",\n",
    "    \"start_year\": 1961,\n",
    "    \"end_year\": 2014,\n",
    "    \"forecast_range\": \"2-9\",\n",
    "    \"lag\": 4,\n",
    "    \"method\": \"nao_matched\",\n",
    "}\n",
    "\n",
    "# Set up the model config for 850U\n",
    "model_config_850u = {\n",
    "    \"variable\": \"ua\",\n",
    "    \"season\": \"ONDJFM\",\n",
    "    \"region\": \"global\",\n",
    "    \"nao\": \"nao_default\",\n",
    "    \"start_year\": 1961,\n",
    "    \"end_year\": 2014,\n",
    "    \"forecast_range\": \"2-9\",\n",
    "    \"lag\": 4,\n",
    "    \"method\": \"nao_matched\",\n",
    "}\n",
    "\n",
    "# make the list of model configs\n",
    "model_configs = [model_config_sfcWind, model_config_850u]\n",
    "\n",
    "# make the list of model array directories\n",
    "model_arr_dirs = [\n",
    "    \"/gws/nopw/j04/canari/users/benhutch/alternate-lag-processed-data/\",\n",
    "    \"/gws/nopw/j04/canari/users/benhutch/alternate-lag-processed-data/test-sfcWind\",\n",
    "]\n",
    "\n",
    "# test the new function\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solar correlations ###\n",
    "\n",
    "Looking at correlations between climate indices (solar irradiance, NAO, delta P) and countrywide solar power generation from the CLEARHEADS data.\n",
    "\n",
    "The data we want is in:\n",
    "\n",
    "* *NUTS_0_sp_historical.nc* - Hourly area-averaged solar power capacity factors at NUTS0 level across Europe from 1950 to 2020.\n",
    "* *NUTS_0_sp_historical_loc_weighted.nc* - Hourly solar power capacity factors at NUTS0 level across Europe, from 01/01/1950 - 31/12/2020. Data is weighted by the location of known solar panels from Dunnett et al., (2020) and Stowell et al., (2020) for the UK.\n",
    "    * This dataset appears to be buggy, use the former."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ste up the model config\n",
    "# Set up the model config\n",
    "# model_config = {\n",
    "#     \"variable\": \"rsds\",\n",
    "#     \"season\": \"ONDJFM\",\n",
    "#     \"region\": \"global\",\n",
    "#     \"start_year\": 1964,\n",
    "#     \"end_year\": 2014,\n",
    "#     \"forecast_range\": \"2-9\",\n",
    "#     \"lag\": 4,\n",
    "#     \"method\": \"alternate_lag\",\n",
    "# }\n",
    "\n",
    "# rsds_global_ONDJFM_2-9_1961_2014_4_West Mediterranean_nao_matched.csv\n",
    "# model_config = {\n",
    "#     \"variable\": \"psl\",\n",
    "#     \"season\": \"ONDJFM\",\n",
    "#     \"region\": \"global\",\n",
    "#     \"nao\": \"nao_default\",\n",
    "#     \"start_year\": 1961,\n",
    "#     \"end_year\": 2014,\n",
    "#     \"forecast_range\": \"2-9\",\n",
    "#     \"lag\": 4,\n",
    "#     \"method\": \"alternate_lag\",\n",
    "# }\n",
    "\n",
    "# model config for 10m wind speeds\n",
    "model_config = {\n",
    "    \"variable\": \"psl\",\n",
    "    \"season\": \"ONDJFM\",\n",
    "    \"region\": \"global\",\n",
    "    \"nao\": \"thornton_2019_uk\",\n",
    "    \"start_year\": 1961,\n",
    "    \"end_year\": 2014,\n",
    "    \"forecast_range\": \"2-9\",\n",
    "    \"lag\": 4,\n",
    "    \"method\": \"alt_lag\",\n",
    "}\n",
    "\n",
    "# ~/shapefiles/NUTS/NUTS_RG_10M_2021_4326.shp\n",
    "\n",
    "# NUTS_0_wp_ons_sim_1_historical_loc_weighted.n\n",
    "# weighted by location of known and proposed future wind farms\n",
    "\n",
    "# Call the function\n",
    "# TODO: onshore wind correlations\n",
    "dfs = funcs.correlate_nao_uread(\n",
    "    filename=\"EEZ_zones_wp_historical.nc\",\n",
    "    nao_n_grid=dicts.uk_n_box_corrected,\n",
    "    nao_s_grid=dicts.uk_s_box_corrected,\n",
    "    use_model_data=True,\n",
    "    model_config=model_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, merged_df, merged_df_full, corr_df = dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_ts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_ts.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_corr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(shapefile.loc[1991].geometry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Rename the columns\n",
    "# corr_df = corr_df.rename(columns={\n",
    "#     \"correlation\": \"correlation_(hc_nao, onshore_cfs)\",\n",
    "#     \"p-value\": \"p-value_(hc_nao, onshore_cfs)\"\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the data but using delta P instead of the NAO index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nao_df_dir = \"/gws/nopw/j04/canari/users/benhutch/nao_stats_df/\"\n",
    "# nao_df_fname = \"psl_ONDJFM_global_1961_2014_2-9_4_nao_default.csv\"\n",
    "\n",
    "# # # Set up the model config\n",
    "# # model_config = {\n",
    "# #     \"variable\": \"psl\",\n",
    "# #     \"season\": \"ONDJFM\",\n",
    "# #     \"region\": \"global\",\n",
    "# #     \"start_year\": 1961,\n",
    "# #     \"end_year\": 2014,\n",
    "# #     \"forecast_range\": \"2-9\",\n",
    "# #     \"lag\": 4,\n",
    "# #     \"nao\": \"thornton_2019_uk\",\n",
    "# # }\n",
    "\n",
    "# # Set up the model config\n",
    "# model_config = {\n",
    "#     \"variable\": \"psl\",\n",
    "#     \"season\": \"ONDJFM\",\n",
    "#     \"region\": \"global\",\n",
    "#     \"start_year\": 1961,\n",
    "#     \"end_year\": 2014,\n",
    "#     \"forecast_range\": \"2-9\",\n",
    "#     \"lag\": 4,\n",
    "#     \"nao\": \"thornton_2019_uk\",\n",
    "#     \"gridbox\": \"Scandinavia\",\n",
    "#     \"method\": \"nao_matched\",\n",
    "# }\n",
    "\n",
    "\n",
    "# # EEZ_zones_wp_historical.nc\n",
    "# # NUTS_0_HDD_historical_pop_weighted.nc\n",
    "# # test the other function for doing this\n",
    "# # days for cooling degree days\n",
    "# df, merged_df, merged_df_full, corr_df = funcs.correlate_nao_uread(\n",
    "#     filename=\"NUTS_0_HDD_historical_pop_weighted.nc\",\n",
    "#     time_unit=\"d\",\n",
    "#     obs_var=\"msl\",\n",
    "#     avg_grid=dicts.scandi_box,\n",
    "#     use_model_data=True,\n",
    "#     model_config=model_config,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calib_df = funcs.calc_model_nao_gridbox_var_corr(\n",
    "#     nao_df=merged_df_full,\n",
    "#     gridbox=dicts.med_box_focus,\n",
    "#     obs_var=\"ssrd\",\n",
    "#     obs_var_data_path=dicts.regrid_file,\n",
    "#     coeff_fname=\"obs_nao_obs_solar_cfs_slope.csv\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calib_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # reload the functions\n",
    "# import importlib\n",
    "\n",
    "# importlib.reload(funcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test the plotting function\n",
    "# funcs.plot_calib_corr(\n",
    "#     df=calib_df,\n",
    "#     predictand_var=\"ES\",\n",
    "#     index_name=\"Calibrated NAO (hPa)\",\n",
    "#     ylabel=\"Spain solar CF.'s (GW)\",\n",
    "#     zero_line=False,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot the calibrated_model_nao_mean against the var228 anomaly mean\n",
    "# # with seperate y-axes\n",
    "# from scipy.stats import pearsonr\n",
    "\n",
    "# # Create a new figure and an axes\n",
    "# fig, ax1 = plt.subplots()\n",
    "\n",
    "# # Plot the calibrated_model_nao_mean on the first y-axis\n",
    "# ax1.plot(df.index, df[\"calibrated_model_nao_mean\"], color=\"blue\", label=\"nao\")\n",
    "# ax1.set_ylabel(\"pr anomalies (mm/day)\")\n",
    "# # Plot the var228 anomaly mean on the second y-axis\n",
    "# ax1.plot(df.index, df[\"var228 anomaly mean\"], color=\"red\", label=\"var228\")\n",
    "\n",
    "# # show the correlation coefiients\n",
    "# corr, p = pearsonr(df[\"calibrated_model_nao_mean\"], df[\"var228 anomaly mean\"])\n",
    "\n",
    "# # Include a textbox in the top left hand corner with the corr and p values\n",
    "# plt.text(\n",
    "#     0.05,\n",
    "#     0.95,\n",
    "#     f\"Corr: {round(corr, 2)}\\n p-value: {round(p, 2)}\",\n",
    "#     horizontalalignment=\"left\",\n",
    "#     verticalalignment=\"top\",\n",
    "#     transform=plt.gca().transAxes,\n",
    "#     bbox=dict(facecolor=\"white\", alpha=0.5),\n",
    "# )\n",
    "\n",
    "# # Include a horixzontal black dashed line at y=0\n",
    "# plt.axhline(0, color=\"black\", linestyle=\"--\")\n",
    "\n",
    "# # Include a legend\n",
    "# plt.legend(loc=\"upper right\")\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"{p:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the NUTS shapefiles\n",
    "# Load in the shapefile fo the eez data\n",
    "NUTS_shapefile = gpd.read_file(\"~/shapefiles/NUTS/NUTS_RG_10M_2021_4326.shp\")\n",
    "\n",
    "# Restrict to level code 0\n",
    "NUTS_shapefile = NUTS_shapefile[NUTS_shapefile.LEVL_CODE == 0]\n",
    "\n",
    "# Extract the second element of the tuple\n",
    "countries_codes = list(dicts.countries_nuts_id.values())\n",
    "\n",
    "# Limit the gpd to the countries in the dictionary\n",
    "NUTS_shapefile = NUTS_shapefile[NUTS_shapefile.NUTS_ID.isin(countries_codes)]\n",
    "\n",
    "# Keep only the NUTS_ID, NUTS_NAME, and geometry columns\n",
    "NUTS_shapefile = NUTS_shapefile[[\"NUTS_ID\", \"NUTS_NAME\", \"geometry\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUTS_shapefile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the shapefile fo the eez data\n",
    "EEZ_shapefile = gpd.read_file(\"~/shapefiles/EEZ/eez_v12.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EEZ_shapefile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Print all of the column names for the eeZ shapefile\n",
    "# print(EEZ_shapefile.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Throw away all of the columns, apart from \"GEONAME\", 'SOVEREIGN1',\n",
    "# \"ISOSOV1\", \"geometry\"\n",
    "EEZ_shapefile = EEZ_shapefile[[\"GEONAME\", \"SOVEREIGN1\", \"ISO_SOV1\", \"geometry\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EEZ_shapefile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iso_sov1 = EEZ_shapefile[\"ISO_SOV1\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iso_sov1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the values of the region column from corr_df\n",
    "region_values = corr_df.region.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload the dictionary\n",
    "importlib.reload(dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the region values to equivalent iso_sov1 values\n",
    "# using the mapping in the dictionary\n",
    "iso_sov1_values = [dicts.iso_mapping[region] for region in region_values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iso_sov1_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constrain the geo dataframe to only include the iso_sov1 values\n",
    "EEZ_shapefile = EEZ_shapefile[EEZ_shapefile[\"ISO_SOV1\"].isin(iso_sov1_values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find where ISO_SOV1 is equal to \"ITA\"\n",
    "EEZ_shapefile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where corr_df.region passed through iso_mapping dict is\n",
    "# equal to the values in EEZ_shapefile.ISO_SOV1\n",
    "# Add the corresponding correlation and p-value to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter df to only include the rows where GEONAME includes: \"Exclusive Economic Zone\"\n",
    "EEZ_shapefile = EEZ_shapefile[\n",
    "    EEZ_shapefile[\"GEONAME\"].str.contains(\"Exclusive Economic Zone\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EEZ_shapefile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we want to append the correlation and p-value to the dataframe\n",
    "# Add a new column to corr_df called \"ISO_SOV1\"\n",
    "corr_df[\"ISO_SOV1\"] = iso_sov1_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df[\"region\"] == \"EL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over the columns in EEZ_shapefile and add the correlation and p-value\n",
    "# where the ISO_SOV1 values are equal\n",
    "for index, row in EEZ_shapefile.iterrows():\n",
    "    # Extract the ISO_SOV1 value\n",
    "    iso_sov1 = row[\"ISO_SOV1\"]\n",
    "    # Find the index of the row in corr_df that matches the ISO_SOV1\n",
    "    index_corr = corr_df[corr_df[\"ISO_SOV1\"] == iso_sov1].index\n",
    "    # Add the correlation and p-value to the dataframe\n",
    "    EEZ_shapefile.loc[index, \"correlation\"] = corr_df.loc[\n",
    "        index_corr, \"correlation\"\n",
    "    ].values\n",
    "    EEZ_shapefile.loc[index, \"p-value\"] = corr_df.loc[index_corr, \"p-value\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same thing for the NUTS_shapefile\n",
    "for index, row in NUTS_shapefile.iterrows():\n",
    "    # Extract the NUTS_ID value\n",
    "    nuts_id = row[\"NUTS_ID\"]\n",
    "\n",
    "    # Find the index of the row in corr_df that matches the NUTS_ID\n",
    "    index_corr = corr_df[corr_df[\"region\"] == nuts_id].index\n",
    "\n",
    "    if len(index_corr) == 0:\n",
    "        print(f\"No match found for {nuts_id}\")\n",
    "        continue\n",
    "\n",
    "    # Add the correlation and p-value to the dataframe\n",
    "    NUTS_shapefile.loc[index, \"correlation\"] = corr_df.loc[\n",
    "        index_corr, \"correlation\"\n",
    "    ].values\n",
    "\n",
    "    NUTS_shapefile.loc[index, \"p-value\"] = corr_df.loc[index_corr, \"p-value\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EEZ_shapefile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUTS_shapefile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any rows from EEZ shapefile which contain \"(*)\" in the GEONAME column\n",
    "EEZ_shapefile = EEZ_shapefile[~EEZ_shapefile[\"GEONAME\"].str.contains(r\"\\(.*\\)\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EEZ_shapefile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(EEZ_shapefile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the dicts\n",
    "importlib.reload(dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "# Now plot the EEZ_shapefile with the correlation as the color\n",
    "plt.figure(figsize=(10, 10))\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "EEZ_shapefile.plot(\n",
    "    column=\"correlation\",\n",
    "    ax=ax,\n",
    "    legend=True,\n",
    "    cmap=\"coolwarm\",\n",
    "    vmin=-1,\n",
    "    vmax=1,\n",
    "    legend_kwds={\n",
    "        \"label\": \"Correlation\",\n",
    "        \"orientation\": \"horizontal\",\n",
    "        \"shrink\": 0.8,\n",
    "        \"pad\": 0.01,\n",
    "    },\n",
    ")\n",
    "# Use cartopy to add the coastlines\n",
    "ax.coastlines()\n",
    "# Make the colorbar smaller\n",
    "cbar = ax.get_figure().get_axes()[1]\n",
    "cbar.set_ylabel(\"Correlation\", fontsize=12)\n",
    "cbar.tick_params(labelsize=10)\n",
    "\n",
    "# Extract the lats of the northern eu grid box\n",
    "lat1, lat2 = dicts.med_box_focus[\"lat1\"], dicts.med_box_focus[\"lat2\"]\n",
    "lon1, lon2 = dicts.med_box_focus[\"lon1\"], dicts.med_box_focus[\"lon2\"]\n",
    "\n",
    "# # Plot the grid box\n",
    "# plt.plot([lon1, lon2, lon2, lon1, lon1], [lat1, lat1, lat2, lat2, lat1], \"r\")\n",
    "\n",
    "# Include hazels grid box\n",
    "lat1_n, lat2_n = (\n",
    "    dicts.uk_n_box_corrected[\"lat1\"],\n",
    "    dicts.uk_n_box_corrected[\"lat2\"],\n",
    ")\n",
    "lon1_n, lon2_n = (\n",
    "    dicts.uk_n_box_corrected[\"lon1\"],\n",
    "    dicts.uk_n_box_corrected[\"lon2\"],\n",
    ")\n",
    "\n",
    "#Plot the grid box\n",
    "plt.plot(\n",
    "    [lon1_n, lon2_n, lon2_n, lon1_n, lon1_n],\n",
    "    [lat1_n, lat1_n, lat2_n, lat2_n, lat1_n],\n",
    "    \"g\",\n",
    "    label=\"delta P\",\n",
    ")\n",
    "\n",
    "# Include hazels grid box\n",
    "lat1_s, lat2_s = (\n",
    "    dicts.uk_s_box_corrected[\"lat1\"],\n",
    "    dicts.uk_s_box_corrected[\"lat2\"],\n",
    ")\n",
    "lon1_s, lon2_s = (\n",
    "    dicts.uk_s_box_corrected[\"lon1\"],\n",
    "    dicts.uk_s_box_corrected[\"lon2\"],\n",
    ")\n",
    "\n",
    "# Plot the grid box\n",
    "plt.plot(\n",
    "    [lon1_s, lon2_s, lon2_s, lon1_s, lon1_s],\n",
    "    [lat1_s, lat1_s, lat2_s, lat2_s, lat1_s],\n",
    "    \"g\",\n",
    ")\n",
    "\n",
    "# Include ticks for the lat and lon\n",
    "ax.gridlines(draw_labels=True)\n",
    "\n",
    "# include a legend\n",
    "plt.legend()\n",
    "\n",
    "# north_atlantic_grid_plot = {\"lon1\": -15, \"lon2\": 40, \"lat1\": 35, \"lat2\": 80}\n",
    "\n",
    "# Constrain to specific bounds\n",
    "ax.set_xlim(-40, 40)\n",
    "ax.set_ylim(32, 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the dictionary\n",
    "importlib.reload(dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit the EEZ_shapefile to only include only the ISO_SOV1 values\n",
    "# Which are in dicts.eez_agg_countries\n",
    "EEZ_shapefile_n = EEZ_shapefile[EEZ_shapefile[\"ISO_SOV1\"].isin(dicts.eez_agg_countries)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now plot the EEZ_shapefile with the correlation as the color\n",
    "plt.figure(figsize=(10, 10))\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "EEZ_shapefile_n.plot(\n",
    "    column=\"correlation\",\n",
    "    ax=ax,\n",
    "    legend=True,\n",
    "    cmap=\"coolwarm\",\n",
    "    vmin=-1,\n",
    "    vmax=1,\n",
    "    legend_kwds={\n",
    "        \"label\": \"Correlation\",\n",
    "        \"orientation\": \"horizontal\",\n",
    "        \"shrink\": 0.8,\n",
    "        \"pad\": 0.01,\n",
    "    },\n",
    ")\n",
    "# Use cartopy to add the coastlines\n",
    "ax.coastlines()\n",
    "# Make the colorbar smaller\n",
    "cbar = ax.get_figure().get_axes()[1]\n",
    "cbar.set_ylabel(\"Correlation\", fontsize=12)\n",
    "cbar.tick_params(labelsize=10)\n",
    "\n",
    "# Include ticks for the lat and lon\n",
    "ax.gridlines(draw_labels=True)\n",
    "\n",
    "# Constrain to specific bounds\n",
    "ax.set_xlim(-40, 40)\n",
    "ax.set_ylim(32, 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload dicts\n",
    "importlib.reload(dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column in cfs called N_Europe\n",
    "# which is the average of all of the countries (columns) in dicts.eez_agg_countries\n",
    "# Convert to three character names first\n",
    "for key in dicts.iso_mapping:\n",
    "    merged_df_full = merged_df_full.rename(columns={key: dicts.iso_mapping[key]})\n",
    "\n",
    "merged_df_full[\"N_Europe\"] = merged_df_full[dicts.eez_agg_countries].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload functions\n",
    "importlib.reload(funcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the plotting function\n",
    "funcs.plot_time_series(\n",
    "    df=merged_df_full,\n",
    "    predictor_col=\"model_nao_mean\",\n",
    "    predictand_col=\"N_Europe\",\n",
    "    ylabel=\"Model delta P anomaly (hPa)\",\n",
    "    twin_axes=True,\n",
    "    ylabel_2=\"Obs N. Europe CF.'s\",\n",
    "    do_detrend=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Create a plot with two y-axes\n",
    "# Time on the x-axes\n",
    "# The variable on the left y-axes is the NAO anomaly (Pa)\n",
    "# The variable on the right y-axes is the wind power (GW) for N_Europe\n",
    "fig, ax1 = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "# Plot the NAO anomaly\n",
    "ax1.plot(merged_df_full.index, merged_df_full.model_nao_mean / 100, \"b-\")\n",
    "\n",
    "# Set the x-axis label\n",
    "ax1.set_xlabel(\"Time\")\n",
    "\n",
    "# Set the y-axis label\n",
    "ax1.set_ylabel(\"Hindcast NAO anomaly (hPa)\", color=\"b\")\n",
    "\n",
    "# Include a black dashed line for y=0\n",
    "ax1.axhline(0, color=\"black\", linestyle=\"--\")\n",
    "\n",
    "# Set the color of the ticks\n",
    "ax1.tick_params(\"y\", colors=\"b\")\n",
    "\n",
    "# Create a second y-axis\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "# Plot the wind power\n",
    "ax2.plot(merged_df_full.index, merged_df_full.ES, \"r-\")\n",
    "\n",
    "# Set the y-axis label\n",
    "ax2.set_ylabel(\"Spain solar CFs\", color=\"r\")\n",
    "\n",
    "# Set the colour of the ticks\n",
    "ax2.tick_params(\"y\", colors=\"r\")\n",
    "\n",
    "# # Invert the y-axis\n",
    "# ax2.invert_yaxis()\n",
    "\n",
    "# Calculate the correlation between the NAO anomaly and the wind power\n",
    "corr, p = pearsonr(merged_df_full.model_nao_mean, merged_df_full.ES)\n",
    "\n",
    "# Include the correlation and p-value on the plot\n",
    "ax2.text(\n",
    "    0.05,\n",
    "    0.95,\n",
    "    f\"Correlation: {corr:.2f}\\nP-value: {p:.2f}\",\n",
    "    horizontalalignment=\"left\",\n",
    "    verticalalignment=\"top\",\n",
    "    bbox=dict(facecolor=\"white\", alpha=0.5),\n",
    "    transform=ax2.transAxes,\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import linregress\n",
    "\n",
    "# Plot a scatter plot of NAO agaist wind power\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "# Plot the scatter plot\n",
    "plt.scatter(merged_df_full[\"model_nao_mean\"], merged_df_full.N_Europe, color=\"k\")\n",
    "\n",
    "# Include a line of best fit\n",
    "slope, intercept, r_value, p_value, std_err = linregress(\n",
    "    merged_df_full[\"model_nao_mean\"] , merged_df_full.N_Europe\n",
    ")\n",
    "\n",
    "# Plot the line of best fit\n",
    "plt.plot(\n",
    "    merged_df_full[\"model_nao_mean\"],\n",
    "    slope * merged_df_full[\"model_nao_mean\"] + intercept,\n",
    "    color=\"k\",\n",
    ")\n",
    "\n",
    "# Show the values\n",
    "if intercept < 0:\n",
    "    equation = f\"y = {slope:.2f}x - {abs(intercept):.3f}\"\n",
    "else:\n",
    "    equation = f\"y = {slope:.2f}x + {intercept:.3f}\"\n",
    "\n",
    "# plt.text(\n",
    "#     0.05,\n",
    "#     0.95,\n",
    "#     f\"{equation}\\nr={r_value:.2f}, p={p_value:.2f}\",\n",
    "#     horizontalalignment=\"left\",\n",
    "#     verticalalignment=\"top\",\n",
    "#     transform=plt.gca().transAxes,\n",
    "#     bbox=dict(facecolor=\"white\", alpha=0.5),\n",
    "# )\n",
    "\n",
    "# Set the x-axis label\n",
    "plt.xlabel(\"Model delta P anomalies (hPa)\", color=\"k\")\n",
    "\n",
    "# Set the xticks to blue\n",
    "plt.tick_params(axis=\"x\", colors=\"k\")\n",
    "\n",
    "# Set the y-axis label\n",
    "plt.ylabel(\"Obs N. Europe CF.'s\", color=\"k\")\n",
    "\n",
    "# Set the yticks to red\n",
    "plt.tick_params(axis=\"y\", colors=\"k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a dataframe to store the values\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"slope\": [slope],\n",
    "        \"intercept\": [intercept],\n",
    "        \"r_value\": [r_value],\n",
    "        \"p_value\": [p_value],\n",
    "        \"std_err\": [std_err],\n",
    "    }\n",
    ")\n",
    "\n",
    "# Set up a filename for the dataframe\n",
    "dir = \"/home/users/benhutch/energy-met-corr/coeffs\"\n",
    "\n",
    "# If the directory does not exist, create it\n",
    "if not os.path.exists(dir):\n",
    "    os.makedirs(dir)\n",
    "\n",
    "# Set up the filename\n",
    "fname = \"obs_nao_obs_solar_cfs_slope.csv\"\n",
    "\n",
    "# set up the full path\n",
    "fpath = os.path.join(dir, fname)\n",
    "\n",
    "# Save the datafram\n",
    "df.to_csv(fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the ERA5 data for the NAO index\n",
    "# Use this file\n",
    "# adaptor.mars.internal-1691509121.3261805-29348-4-3a487c76-fc7b-421f-b5be-7436e2eb78d7.nc\n",
    "# in ~/ERA5/\n",
    "# Load the dataset\n",
    "era5_data_path = \"~/ERA5/adaptor.mars.internal-1691509121.3261805-29348-4-3a487c76-fc7b-421f-b5be-7436e2eb78d7.nc\"\n",
    "\n",
    "# Load the data into chunks\n",
    "ds_era5 = xr.open_mfdataset(\n",
    "    era5_data_path,\n",
    "    combine=\"by_coords\",\n",
    "    parallel=True,\n",
    "    chunks={\"time\": 100, \"latitude\": 100, \"longitude\": 100},\n",
    ")[\n",
    "    \"msl\"\n",
    "]  # for mean sea level pressure\n",
    "\n",
    "# Combine the first two expver variables\n",
    "obs_msl = ds_era5.sel(expver=1).combine_first(ds_era5.sel(expver=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constrain obs to ONDJFM\n",
    "obs_msl = obs_msl.sel(time=obs_msl.time.dt.month.isin([10, 11, 12, 1, 2, 3]))\n",
    "\n",
    "# Shift the time index back by 3 months\n",
    "obs_msl_shifted = obs_msl.shift(time=-3)\n",
    "\n",
    "# Take annual means\n",
    "obs_msl_annual = obs_msl_shifted.resample(time=\"Y\").mean()\n",
    "\n",
    "# Throw away years 1959, 2021, 2022 and 2023\n",
    "obs_msl_annual = obs_msl_annual.sel(time=slice(\"1960\", \"2019\"))\n",
    "\n",
    "# Remove the climatology\n",
    "obs_msl_anomaly = obs_msl_annual - obs_msl_annual.mean(dim=\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the lats and lons of the azores\n",
    "lat1, lat2 = dicts.era5_azores[\"lat1\"], dicts.era5_azores[\"lat2\"]\n",
    "lon1, lon2 = dicts.era5_azores[\"lon1\"], dicts.era5_azores[\"lon2\"]\n",
    "\n",
    "# Calculate the mean for the azores gridbox\n",
    "obs_msl_anomaly_azores = obs_msl_anomaly.sel(\n",
    "    latitude=slice(lat1, lat2), longitude=slice(lon1, lon2)\n",
    ").mean(dim=[\"latitude\", \"longitude\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same for iceland\n",
    "lat1, lat2 = dicts.era5_iceland[\"lat1\"], dicts.era5_iceland[\"lat2\"]\n",
    "lon1, lon2 = dicts.era5_iceland[\"lon1\"], dicts.era5_iceland[\"lon2\"]\n",
    "\n",
    "# Calculate the mean for the iceland gridbox\n",
    "obs_msl_anomaly_iceland = obs_msl_anomaly.sel(\n",
    "    latitude=slice(lat1, lat2), longitude=slice(lon1, lon2)\n",
    ").mean(dim=[\"latitude\", \"longitude\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the NAO index (azores - iceland)\n",
    "nao_index = obs_msl_anomaly_azores - obs_msl_anomaly_iceland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXtract the time series\n",
    "nao_index_time = nao_index.time.values\n",
    "\n",
    "# Extract the values\n",
    "nao_index_values = nao_index.values\n",
    "\n",
    "# Create a dataframe\n",
    "nao_df = pd.DataFrame({\"time\": nao_index_time, \"value\": nao_index_values})\n",
    "\n",
    "# Take a centred 8-year running mean\n",
    "nao_running = nao_df.set_index(\"time\").rolling(8, center=True).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have a look at the dataframe\n",
    "nao_running.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the NaN values\n",
    "nao_running = nao_running.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the two dataframes into one, using the index of the first\n",
    "eez_df = eez_cfs.join(nao_running, how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eez_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the value column as 'NAO anomaly (Pa)'\n",
    "eez_df = eez_df.rename(columns={\"value\": \"NAO anomaly (Pa)\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the rows which contain NaN values in the NAO anomaly column\n",
    "eez_df = eez_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eez_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "import pandas as pd\n",
    "\n",
    "# Create a new dataframe with columns for:\n",
    "# 'region' - e.g. Netherlands_7\n",
    "# 'correlation' - the correlation between the NAO and the offshore wind CFs\n",
    "# 'p-value' - the p-value of the correlation\n",
    "# Set up the dataframe\n",
    "correlation_df = pd.DataFrame(columns=[\"region\", \"correlation\", \"p-value\"])\n",
    "\n",
    "# Loop over the regions\n",
    "for region in eez_df.columns[:-1]:\n",
    "    # Calculate the correlation\n",
    "    corr, p = pearsonr(eez_df[region], eez_df[\"NAO anomaly (Pa)\"])\n",
    "\n",
    "    # Create a new DataFrame to append\n",
    "    df_to_append = pd.DataFrame(\n",
    "        {\"region\": [region], \"correlation\": [corr], \"p-value\": [p]}\n",
    "    )\n",
    "\n",
    "    # Append to the dataframe\n",
    "    correlation_df = pd.concat([correlation_df, df_to_append], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the numbers from the region column by removing the last 2 characters\n",
    "correlation_df[\"region\"] = correlation_df[\"region\"].str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if any of the region names contain the string \"_\" then remove it\n",
    "correlation_df[\"region\"] = correlation_df[\"region\"].str.replace(\"_\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EEZ_shapefile[\"SOVEREIGN1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two new columns in the geopandas dataframe 'EEZ_shapefile'\n",
    "# 'correlation' - the correlation between the NAO and the offshore wind CFs\n",
    "# 'p-value' - the p-value of the correlation\n",
    "EEZ_shapefile[\"correlation\"] = np.nan\n",
    "EEZ_shapefile[\"p-value\"] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EEZ_shapefile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over the regions in correlation_df\n",
    "for region in correlation_df[\"region\"]:\n",
    "    # Extract the row from correlation_df\n",
    "    row = correlation_df[correlation_df[\"region\"] == region]\n",
    "\n",
    "    # Extract the correlation and p-value\n",
    "    corr = row[\"correlation\"].values[0]\n",
    "    p = row[\"p-value\"].values[0]\n",
    "\n",
    "    # Set the values in the EEZ_shapefile\n",
    "    EEZ_shapefile.loc[EEZ_shapefile[\"TERRITORY1\"] == region, \"correlation\"] = corr\n",
    "    EEZ_shapefile.loc[EEZ_shapefile[\"TERRITORY1\"] == region, \"p-value\"] = p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EEZ_shapefile[\"TERRITORY1\"] == \"France\", \"correlation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the list of Terrirories\n",
    "territories = EEZ_shapefile[\"TERRITORY1\"]\n",
    "\n",
    "# Convert to a list\n",
    "territories = list(territories)\n",
    "\n",
    "# Print the territories\n",
    "print(territories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constrain EEZ shapefile to only include the territories in the list\n",
    "EEZ_shapefile = EEZ_shapefile[EEZ_shapefile[\"TERRITORY1\"].isin(dicts.countries_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the correlation values for FRance\n",
    "print(EEZ_shapefile[EEZ_shapefile[\"SOVEREIGN1\"] == \"France\"][\"correlation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "# Now plot the EEZ_shapefile with the correlation as the color\n",
    "plt.figure(figsize=(10, 10))\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "EEZ_shapefile.plot(\n",
    "    column=\"correlation\", ax=ax, legend=True, cmap=\"coolwarm\", shrink=0.5\n",
    ")\n",
    "# Use cartopy to add the coastlines\n",
    "ax.coastlines()\n",
    "# Make the colorbar smaller\n",
    "cbar = ax.get_figure().get_axes()[1]\n",
    "cbar.set_ylabel(\"Correlation\", fontsize=12)\n",
    "cbar.tick_params(labelsize=10)\n",
    "\n",
    "# Constrain to specific bounds\n",
    "ax.set_xlim(-50, 50)\n",
    "ax.set_ylim(30, 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now plot the EEZ_shapefile with the correlation as the color\n",
    "fig, ax = plt.subplots(figsize=(10, 10), subplot_kw={\"projection\": ccrs.PlateCarree()})\n",
    "cax = EEZ_shapefile.plot(\n",
    "    column=\"correlation\", ax=ax, cmap=\"coolwarm\", add_colorbar=False\n",
    ")\n",
    "\n",
    "# Use cartopy to add the coastlines\n",
    "ax.coastlines()\n",
    "\n",
    "# Add colorbar\n",
    "cbar = fig.colorbar(cax.collections[0], ax=ax, shrink=0.5)\n",
    "cbar.set_label(\"Correlation\")\n",
    "\n",
    "# Constrain to specific bounds\n",
    "ax.set_xlim(-50, 50)\n",
    "ax.set_ylim(30, 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
