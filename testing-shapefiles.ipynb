{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the relevant modules\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "\n",
    "# Import third party modules\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dictionaries_em as dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"/home/users/benhutch/energy-met-corr-functions\")\n",
    "\n",
    "# Import the functions\n",
    "import functions_em as funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "importlib.reload(funcs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate onshore wind correlations ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solar correlations ###\n",
    "\n",
    "Looking at correlations between climate indices (solar irradiance, NAO, delta P) and countrywide solar power generation from the CLEARHEADS data.\n",
    "\n",
    "The data we want is in:\n",
    "\n",
    "* *NUTS_0_sp_historical.nc* - Hourly area-averaged solar power capacity factors at NUTS0 level across Europe from 1950 to 2020.\n",
    "* *NUTS_0_sp_historical_loc_weighted.nc* - Hourly solar power capacity factors at NUTS0 level across Europe, from 01/01/1950 - 31/12/2020. Data is weighted by the location of known solar panels from Dunnett et al., (2020) and Stowell et al., (2020) for the UK.\n",
    "    * This dataset appears to be buggy, use the former."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Ste up the model config\n",
    "# Set up the model config\n",
    "# model_config = {\n",
    "#     \"variable\": \"rsds\",\n",
    "#     \"season\": \"ONDJFM\",\n",
    "#     \"region\": \"global\",\n",
    "#     \"start_year\": 1964,\n",
    "#     \"end_year\": 2014,\n",
    "#     \"forecast_range\": \"2-9\",\n",
    "#     \"lag\": 4,\n",
    "#     \"method\": \"alternate_lag\",\n",
    "# }\n",
    "\n",
    "# # rsds_global_ONDJFM_2-9_1961_2014_4_West Mediterranean_nao_matched.csv\n",
    "model_config = {\n",
    "    \"variable\": \"psl\",\n",
    "    \"season\": \"ONDJFM\",\n",
    "    \"region\": \"global\",\n",
    "    \"nao\": \"nao_default\",\n",
    "    \"start_year\": 1961,\n",
    "    \"end_year\": 2014,\n",
    "    \"forecast_range\": \"2-9\",\n",
    "    \"lag\": 4,\n",
    "    \"method\": \"alternate_lag\",\n",
    "}\n",
    "\n",
    "# file=\"NUTS_0_t2m_detrended_timeseries_historical_pop_weighted.nc\",\n",
    "# shp_file=\"NUTS_RG_10M_2021_4326.shp\",\n",
    "# shp_file_dir=\"/home/users/benhutch/shapefiles/NUTS/\",\n",
    "# label=\"Pop. weighted temp (K)\",\n",
    "# trend_level=2020.0,\n",
    "# tas_global_ONDJFM_2-9_1961_2014_4_UK_grid_nao_matched.csv\n",
    "\n",
    "# # model config for 10m wind speeds\n",
    "# model_config = {\n",
    "#     \"variable\": \"tas\",\n",
    "#     \"season\": \"ONDJFM\",\n",
    "#     \"region\": \"global\",\n",
    "#     \"start_year\": 1961,\n",
    "#     \"end_year\": 2014,\n",
    "#     \"forecast_range\": \"2-9\",\n",
    "#     \"lag\": 4,\n",
    "#     \"gridbox\": \"UK_grid\",\n",
    "#     \"method\": \"nao_matched\",\n",
    "# }\n",
    "\n",
    "# ~/shapefiles/NUTS/NUTS_RG_10M_2021_4326.shp\n",
    "\n",
    "# NUTS_0_wp_ons_sim_1_historical_loc_weighted.n\n",
    "# weighted by location of known and proposed future wind farms\n",
    "# gws/nopw/j04/canari/users/benhutch/nao_stats_df/tas_global_ONDJFM_2-9_1961_2014_4_UK_grid_nao_matched.csv\n",
    "# /gws/nopw/j04/canari/users/benhutch/nao_stats_df/psl_ONDJFM_global_1961_2014_2-9_4_nao_default.csv\n",
    "\n",
    "# Call the function\n",
    "# TODO: onshore wind correlations\n",
    "dfs_model_NAO = funcs.correlate_nao_uread(\n",
    "    filename=\"NUTS_0_sp_historical.nc\",\n",
    "    use_model_data=True,\n",
    "    model_config=model_config,\n",
    ")\n",
    "\n",
    "# use_model_data=True,\n",
    "# model_config=model_config,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_obs_pr = funcs.correlate_nao_uread(\n",
    "    filename=\"NUTS_0_sp_historical.nc\",\n",
    "    obs_var=\"var228\",\n",
    "    obs_var_data_path=dicts.regrid_file_pr,\n",
    "    avg_grid=dicts.scandi_box,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dfs_model_NAO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, merged_df_NAO, _ = dfs_model_NAO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df, _ = dfs_obs_pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_NAO.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_NAO = merged_df_NAO[[\"model_nao_mean\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_NAO.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df[[\"var228 anomaly mean\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert index to years\n",
    "merged_df.index = merged_df.index.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_nao_pr = merged_df_NAO.join(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_nao_pr.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_pr = merged_df[[\"var228 anomaly mean\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restrict to the \"NAO anomaly (Pa)\" column\n",
    "merged_df_NAO = merged_df[[\"NAO anomaly (Pa)\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_NAO.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_pr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join the two dataframes\n",
    "merged_df = merged_df_NAO.join(merged_df_pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, df_model, merged_df, corr_df = dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # restrict merged_df to the index, fcst_ts_mean and obs_ts and UK\n",
    "# merged_df_subset = merged_df[[\n",
    "#     \"fcst_ts_mean\",\n",
    "#     \"obs_ts\",\n",
    "#     \"UK\",\n",
    "# ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_df_subset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to file\n",
    "path = \"/home/users/benhutch/energy-sotcr-2023/data/ERA5_wd_demand_UK_1940_2023_daily.csv\"\n",
    "\n",
    "# open the file\n",
    "demand_df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demand_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process the data\n",
    "demand_df[\"date\"] = pd.to_datetime(demand_df[\"Unnamed: 0\"])\n",
    "\n",
    "# set the date as the index\n",
    "demand_df.set_index(\"date\", inplace=True)\n",
    "\n",
    "# drop the unnamed column\n",
    "demand_df.drop(\"Unnamed: 0\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resample into monthly means\n",
    "demand_monthly = demand_df.resample(\"M\").mean()\n",
    "\n",
    "# Select only the period of interest\n",
    "demand_monthly = demand_monthly.loc[\"1960-01-01\":\"2023-12-31\"]\n",
    "\n",
    "# Select the months of interest\n",
    "demand_monthly = demand_monthly[demand_monthly.index.month.isin([10, 11, 12, 1, 2, 3])]\n",
    "\n",
    "# shift by the annual offset\n",
    "demand_monthly.index = demand_monthly.index - pd.DateOffset(months=3)\n",
    "\n",
    "# Throw away the first 3 months and the last 3 months\n",
    "demand_monthly = demand_monthly[3:-3]\n",
    "\n",
    "# Calculate the annual average\n",
    "demand_annual = demand_monthly.resample(\"Y\").mean()\n",
    "\n",
    "# Take the rolling mean\n",
    "demand_rolling = demand_annual.rolling(window=8, center=True).mean()\n",
    "\n",
    "# throw away the NaN values\n",
    "demand_rolling = demand_rolling.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename United_Kingdom to UK_wd_demand\n",
    "demand_rolling.rename(columns={\"United_Kingdom\": \"UK_wd_demand\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demand_rolling.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the index of the demand_rolling to be the date in years + 5\n",
    "demand_rolling.index = demand_rolling.index\n",
    "\n",
    "# set just as the years\n",
    "demand_rolling.index = demand_rolling.index.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join the two dataframes: merged_df and demand_rolling\n",
    "combined_df = merged_df.join(demand_rolling, how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# throw away all columns apart from the UK_wd_demand and \"t2m anomaly mean\"\n",
    "combined_df_subset = combined_df[[\"UK_wd_demand\", \"fcst_ts_mean\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df_subset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'date' column to datetime format\n",
    "demand_df['date'] = pd.to_datetime(demand_df['date'])\n",
    "\n",
    "# Extract the year and set it as the index\n",
    "demand_df['year'] = demand_df['date'].dt.year\n",
    "demand_df.set_index('year', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "demand_df = demand_df.drop('date', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "demand_df = demand_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join the dataframes\n",
    "merged_df = merged_df_subset.join(demand_df, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restrict to NAO anomaly (Pa) column\n",
    "merged_df = merged_df[\"UK\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the Series to a DataFrame\n",
    "merged_df = merged_df.to_frame()\n",
    "\n",
    "# Reset the index\n",
    "merged_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the file\n",
    "# # output directory\n",
    "output_dir = \"/home/users/benhutch/NGrid_demand/csv_files\"\n",
    "\n",
    "# output filename\n",
    "output_fname = \"obs_UK_historical_temp_detrend_0.csv\"\n",
    "\n",
    "# Save as a csv file\n",
    "# save the dataframe to a .csv file\n",
    "merged_df.to_csv(os.path.join(output_dir, output_fname), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df, merged_df, merged_df_full, corr_df = dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_df_hdd = merged_df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_df_hdd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfs_ofs_wind = funcs.correlate_nao_uread(\n",
    "#     filename=\"EEZ_zones_wp_historical.nc\",\n",
    "#     nao_n_grid=dicts.uk_n_box_corrected,\n",
    "#     nao_s_grid=dicts.uk_s_box_corrected,\n",
    "#     use_model_data=True,\n",
    "#     model_config=model_config,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(dfs_ofs_wind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _, _, merged_df_full, _ = dfs_ofs_wind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Combine these two datasets together\n",
    "# # HDD - offshore wind\n",
    "# # add suffixes\n",
    "# merged_df_hdd = merged_df_hdd.add_suffix(\"_HDD\")\n",
    "# merged_df_wind = merged_df_full.add_suffix(\"_ofs_wind\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # join the two dataframes\n",
    "# hdd_wind = merged_df_hdd.join(merged_df_wind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hdd_wind.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a new dataframe\n",
    "# demand_net_wind = pd.DataFrame()\n",
    "\n",
    "# # Loop over the columns\n",
    "# for column in hdd_wind.columns:\n",
    "#     if column.endswith('_HDD'):\n",
    "#         country_code = column[:2]  # Get the country code\n",
    "#         if f\"{country_code}_ofs_wind\" in hdd_wind.columns:\n",
    "#             # Standardize the columns before taking the difference\n",
    "#             hdd_standardized = (hdd_wind[column] - hdd_wind[column].mean()) / hdd_wind[column].std()\n",
    "#             ofs_wind_standardized = (hdd_wind[f\"{country_code}_ofs_wind\"] - hdd_wind[f\"{country_code}_ofs_wind\"].mean()) / hdd_wind[f\"{country_code}_ofs_wind\"].std()\n",
    "            \n",
    "#             demand_net_wind[f'{country_code}_diff'] = hdd_standardized - ofs_wind_standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demand_net_wind.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demand_net_wind[\"model_NAO_anomaly_(hPa)\"] = hdd_wind['model_nao_mean_ofs_wind']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.stats import pearsonr\n",
    "\n",
    "# # Create an empty list to store the data\n",
    "# data = []\n",
    "\n",
    "# # Loop over the columns\n",
    "# for column in demand_net_wind.columns:\n",
    "#     if column.endswith('_diff'):\n",
    "#         # Extract the country code\n",
    "#         country_code = column[:2]\n",
    "\n",
    "#         if not demand_net_wind[column].isna().any():\n",
    "#             # Calculate the correlation and p-value\n",
    "#             corr, p_value = pearsonr(demand_net_wind[column], demand_net_wind['model_NAO_anomaly_(hPa)'])\n",
    "        \n",
    "#             # Append the results to the data list\n",
    "#             data.append([country_code, corr, p_value])\n",
    "#         else:\n",
    "#             data.append([country_code, np.nan, np.nan])\n",
    "\n",
    "# # Convert the data list to a dataframe\n",
    "# diff_cor_df = pd.DataFrame(data, columns=['Country Code', 'Correlation', 'P-Value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hdd_wind.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diff_cor_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Rename the columns\n",
    "# corr_df = corr_df.rename(columns={\n",
    "#     \"correlation\": \"correlation_(hc_nao, onshore_cfs)\",\n",
    "#     \"p-value\": \"p-value_(hc_nao, onshore_cfs)\"\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demand_net_wind.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the data but using delta P instead of the NAO index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nao_df_dir = \"/gws/nopw/j04/canari/users/benhutch/nao_stats_df/\"\n",
    "# nao_df_fname = \"psl_ONDJFM_global_1961_2014_2-9_4_nao_default.csv\"\n",
    "\n",
    "# # # Set up the model config\n",
    "# # model_config = {\n",
    "# #     \"variable\": \"psl\",\n",
    "# #     \"season\": \"ONDJFM\",\n",
    "# #     \"region\": \"global\",\n",
    "# #     \"start_year\": 1961,\n",
    "# #     \"end_year\": 2014,\n",
    "# #     \"forecast_range\": \"2-9\",\n",
    "# #     \"lag\": 4,\n",
    "# #     \"nao\": \"thornton_2019_uk\",\n",
    "# # }\n",
    "\n",
    "# # Set up the model config\n",
    "# model_config = {\n",
    "#     \"variable\": \"psl\",\n",
    "#     \"season\": \"ONDJFM\",\n",
    "#     \"region\": \"global\",\n",
    "#     \"start_year\": 1961,\n",
    "#     \"end_year\": 2014,\n",
    "#     \"forecast_range\": \"2-9\",\n",
    "#     \"lag\": 4,\n",
    "#     \"nao\": \"thornton_2019_uk\",\n",
    "#     \"gridbox\": \"Scandinavia\",\n",
    "#     \"method\": \"nao_matched\",\n",
    "# }\n",
    "\n",
    "\n",
    "# # EEZ_zones_wp_historical.nc\n",
    "# # NUTS_0_HDD_historical_pop_weighted.nc\n",
    "# # test the other function for doing this\n",
    "# # days for cooling degree days\n",
    "# df, merged_df, merged_df_full, corr_df = funcs.correlate_nao_uread(\n",
    "#     filename=\"NUTS_0_HDD_historical_pop_weighted.nc\",\n",
    "#     time_unit=\"d\",\n",
    "#     obs_var=\"msl\",\n",
    "#     avg_grid=dicts.scandi_box,\n",
    "#     use_model_data=True,\n",
    "#     model_config=model_config,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calib_df = funcs.calc_model_nao_gridbox_var_corr(\n",
    "#     nao_df=merged_df_full,\n",
    "#     gridbox=dicts.med_box_focus,\n",
    "#     obs_var=\"ssrd\",\n",
    "#     obs_var_data_path=dicts.regrid_file,\n",
    "#     coeff_fname=\"obs_nao_obs_solar_cfs_slope.csv\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calib_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # reload the functions\n",
    "# import importlib\n",
    "\n",
    "# importlib.reload(funcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test the plotting function\n",
    "# funcs.plot_calib_corr(\n",
    "#     df=calib_df,\n",
    "#     predictand_var=\"ES\",\n",
    "#     index_name=\"Calibrated NAO (hPa)\",\n",
    "#     ylabel=\"Spain solar CF.'s (GW)\",\n",
    "#     zero_line=False,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot the calibrated_model_nao_mean against the var228 anomaly mean\n",
    "# # with seperate y-axes\n",
    "# from scipy.stats import pearsonr\n",
    "\n",
    "# # Create a new figure and an axes\n",
    "# fig, ax1 = plt.subplots()\n",
    "\n",
    "# # Plot the calibrated_model_nao_mean on the first y-axis\n",
    "# ax1.plot(df.index, df[\"calibrated_model_nao_mean\"], color=\"blue\", label=\"nao\")\n",
    "# ax1.set_ylabel(\"pr anomalies (mm/day)\")\n",
    "# # Plot the var228 anomaly mean on the second y-axis\n",
    "# ax1.plot(df.index, df[\"var228 anomaly mean\"], color=\"red\", label=\"var228\")\n",
    "\n",
    "# # show the correlation coefiients\n",
    "# corr, p = pearsonr(df[\"calibrated_model_nao_mean\"], df[\"var228 anomaly mean\"])\n",
    "\n",
    "# # Include a textbox in the top left hand corner with the corr and p values\n",
    "# plt.text(\n",
    "#     0.05,\n",
    "#     0.95,\n",
    "#     f\"Corr: {round(corr, 2)}\\n p-value: {round(p, 2)}\",\n",
    "#     horizontalalignment=\"left\",\n",
    "#     verticalalignment=\"top\",\n",
    "#     transform=plt.gca().transAxes,\n",
    "#     bbox=dict(facecolor=\"white\", alpha=0.5),\n",
    "# )\n",
    "\n",
    "# # Include a horixzontal black dashed line at y=0\n",
    "# plt.axhline(0, color=\"black\", linestyle=\"--\")\n",
    "\n",
    "# # Include a legend\n",
    "# plt.legend(loc=\"upper right\")\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"{p:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the NUTS shapefiles\n",
    "# Load in the shapefile fo the eez data\n",
    "NUTS_shapefile = gpd.read_file(\"~/shapefiles/NUTS/NUTS_RG_10M_2021_4326.shp\")\n",
    "\n",
    "# Restrict to level code 0\n",
    "NUTS_shapefile = NUTS_shapefile[NUTS_shapefile.LEVL_CODE == 0]\n",
    "\n",
    "# Extract the second element of the tuple\n",
    "countries_codes = list(dicts.countries_nuts_id.values())\n",
    "\n",
    "# Limit the gpd to the countries in the dictionary\n",
    "NUTS_shapefile = NUTS_shapefile[NUTS_shapefile.NUTS_ID.isin(countries_codes)]\n",
    "\n",
    "# Keep only the NUTS_ID, NUTS_NAME, and geometry columns\n",
    "NUTS_shapefile = NUTS_shapefile[[\"NUTS_ID\", \"NUTS_NAME\", \"geometry\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUTS_shapefile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the shapefile fo the eez data\n",
    "EEZ_shapefile = gpd.read_file(\"~/shapefiles/EEZ/eez_v12.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EEZ_shapefile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Print all of the column names for the eeZ shapefile\n",
    "# print(EEZ_shapefile.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Throw away all of the columns, apart from \"GEONAME\", 'SOVEREIGN1',\n",
    "# \"ISOSOV1\", \"geometry\"\n",
    "EEZ_shapefile = EEZ_shapefile[[\"GEONAME\", \"SOVEREIGN1\", \"ISO_SOV1\", \"geometry\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EEZ_shapefile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iso_sov1 = EEZ_shapefile[\"ISO_SOV1\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iso_sov1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the values of the region column from corr_df\n",
    "region_values = corr_df.region.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload the dictionary\n",
    "importlib.reload(dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the region values to equivalent iso_sov1 values\n",
    "# using the mapping in the dictionary\n",
    "iso_sov1_values = [dicts.iso_mapping[region] for region in region_values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iso_sov1_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constrain the geo dataframe to only include the iso_sov1 values\n",
    "EEZ_shapefile = EEZ_shapefile[EEZ_shapefile[\"ISO_SOV1\"].isin(iso_sov1_values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find where ISO_SOV1 is equal to \"ITA\"\n",
    "EEZ_shapefile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where corr_df.region passed through iso_mapping dict is\n",
    "# equal to the values in EEZ_shapefile.ISO_SOV1\n",
    "# Add the corresponding correlation and p-value to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter df to only include the rows where GEONAME includes: \"Exclusive Economic Zone\"\n",
    "EEZ_shapefile = EEZ_shapefile[\n",
    "    EEZ_shapefile[\"GEONAME\"].str.contains(\"Exclusive Economic Zone\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EEZ_shapefile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we want to append the correlation and p-value to the dataframe\n",
    "# Add a new column to corr_df called \"ISO_SOV1\"\n",
    "corr_df[\"ISO_SOV1\"] = iso_sov1_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df[\"region\"] == \"EL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over the columns in EEZ_shapefile and add the correlation and p-value\n",
    "# where the ISO_SOV1 values are equal\n",
    "for index, row in EEZ_shapefile.iterrows():\n",
    "    # Extract the ISO_SOV1 value\n",
    "    iso_sov1 = row[\"ISO_SOV1\"]\n",
    "    # Find the index of the row in corr_df that matches the ISO_SOV1\n",
    "    index_corr = corr_df[corr_df[\"ISO_SOV1\"] == iso_sov1].index\n",
    "    # Add the correlation and p-value to the dataframe\n",
    "    EEZ_shapefile.loc[index, \"correlation\"] = corr_df.loc[\n",
    "        index_corr, \"correlation\"\n",
    "    ].values\n",
    "    EEZ_shapefile.loc[index, \"p-value\"] = corr_df.loc[index_corr, \"p-value\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same thing for the NUTS_shapefile\n",
    "for index, row in NUTS_shapefile.iterrows():\n",
    "    # Extract the NUTS_ID value\n",
    "    nuts_id = row[\"NUTS_ID\"]\n",
    "\n",
    "    # Find the index of the row in corr_df that matches the NUTS_ID\n",
    "    index_corr = corr_df[corr_df[\"region\"] == nuts_id].index\n",
    "\n",
    "    if len(index_corr) == 0:\n",
    "        print(f\"No match found for {nuts_id}\")\n",
    "        continue\n",
    "\n",
    "    # Add the correlation and p-value to the dataframe\n",
    "    NUTS_shapefile.loc[index, \"correlation\"] = corr_df.loc[\n",
    "        index_corr, \"correlation\"\n",
    "    ].values\n",
    "\n",
    "    NUTS_shapefile.loc[index, \"p-value\"] = corr_df.loc[index_corr, \"p-value\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EEZ_shapefile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUTS_shapefile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any rows from EEZ shapefile which contain \"(*)\" in the GEONAME column\n",
    "EEZ_shapefile = EEZ_shapefile[~EEZ_shapefile[\"GEONAME\"].str.contains(r\"\\(.*\\)\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EEZ_shapefile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(EEZ_shapefile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the dicts\n",
    "importlib.reload(dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "# Now plot the EEZ_shapefile with the correlation as the color\n",
    "plt.figure(figsize=(10, 10))\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "EEZ_shapefile.plot(\n",
    "    column=\"correlation\",\n",
    "    ax=ax,\n",
    "    legend=True,\n",
    "    cmap=\"coolwarm\",\n",
    "    vmin=-1,\n",
    "    vmax=1,\n",
    "    legend_kwds={\n",
    "        \"label\": \"Correlation\",\n",
    "        \"orientation\": \"horizontal\",\n",
    "        \"shrink\": 0.8,\n",
    "        \"pad\": 0.01,\n",
    "    },\n",
    ")\n",
    "# Use cartopy to add the coastlines\n",
    "ax.coastlines()\n",
    "# Make the colorbar smaller\n",
    "cbar = ax.get_figure().get_axes()[1]\n",
    "cbar.set_ylabel(\"Correlation\", fontsize=12)\n",
    "cbar.tick_params(labelsize=10)\n",
    "\n",
    "# Extract the lats of the northern eu grid box\n",
    "lat1, lat2 = dicts.med_box_focus[\"lat1\"], dicts.med_box_focus[\"lat2\"]\n",
    "lon1, lon2 = dicts.med_box_focus[\"lon1\"], dicts.med_box_focus[\"lon2\"]\n",
    "\n",
    "# # Plot the grid box\n",
    "# plt.plot([lon1, lon2, lon2, lon1, lon1], [lat1, lat1, lat2, lat2, lat1], \"r\")\n",
    "\n",
    "# Include hazels grid box\n",
    "lat1_n, lat2_n = (\n",
    "    dicts.uk_n_box_corrected[\"lat1\"],\n",
    "    dicts.uk_n_box_corrected[\"lat2\"],\n",
    ")\n",
    "lon1_n, lon2_n = (\n",
    "    dicts.uk_n_box_corrected[\"lon1\"],\n",
    "    dicts.uk_n_box_corrected[\"lon2\"],\n",
    ")\n",
    "\n",
    "#Plot the grid box\n",
    "plt.plot(\n",
    "    [lon1_n, lon2_n, lon2_n, lon1_n, lon1_n],\n",
    "    [lat1_n, lat1_n, lat2_n, lat2_n, lat1_n],\n",
    "    \"g\",\n",
    "    label=\"delta P\",\n",
    ")\n",
    "\n",
    "# Include hazels grid box\n",
    "lat1_s, lat2_s = (\n",
    "    dicts.uk_s_box_corrected[\"lat1\"],\n",
    "    dicts.uk_s_box_corrected[\"lat2\"],\n",
    ")\n",
    "lon1_s, lon2_s = (\n",
    "    dicts.uk_s_box_corrected[\"lon1\"],\n",
    "    dicts.uk_s_box_corrected[\"lon2\"],\n",
    ")\n",
    "\n",
    "# Plot the grid box\n",
    "plt.plot(\n",
    "    [lon1_s, lon2_s, lon2_s, lon1_s, lon1_s],\n",
    "    [lat1_s, lat1_s, lat2_s, lat2_s, lat1_s],\n",
    "    \"g\",\n",
    ")\n",
    "\n",
    "# Include ticks for the lat and lon\n",
    "ax.gridlines(draw_labels=True)\n",
    "\n",
    "# include a legend\n",
    "plt.legend()\n",
    "\n",
    "# north_atlantic_grid_plot = {\"lon1\": -15, \"lon2\": 40, \"lat1\": 35, \"lat2\": 80}\n",
    "\n",
    "# Constrain to specific bounds\n",
    "ax.set_xlim(-40, 40)\n",
    "ax.set_ylim(32, 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the dictionary\n",
    "importlib.reload(dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit the EEZ_shapefile to only include only the ISO_SOV1 values\n",
    "# Which are in dicts.eez_agg_countries\n",
    "EEZ_shapefile_n = EEZ_shapefile[EEZ_shapefile[\"ISO_SOV1\"].isin(dicts.eez_agg_countries)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now plot the EEZ_shapefile with the correlation as the color\n",
    "plt.figure(figsize=(10, 10))\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "EEZ_shapefile_n.plot(\n",
    "    column=\"correlation\",\n",
    "    ax=ax,\n",
    "    legend=True,\n",
    "    cmap=\"bwr\",\n",
    "    vmin=-1,\n",
    "    vmax=1,\n",
    "    legend_kwds={\n",
    "        \"label\": \"Pearson correlation with ONDJFM delta P index\",\n",
    "        \"orientation\": \"horizontal\",\n",
    "        \"shrink\": 0.8,\n",
    "        \"pad\": 0.01,\n",
    "    },\n",
    ")\n",
    "# Use cartopy to add the coastlines\n",
    "ax.coastlines()\n",
    "# Make the colorbar smaller\n",
    "cbar = ax.get_figure().get_axes()[1]\n",
    "cbar.set_ylabel(\"Pearson correlation with delta P index\", fontsize=12)\n",
    "cbar.tick_params(labelsize=10)\n",
    "\n",
    "# Include ticks for the lat and lon\n",
    "ax.gridlines(draw_labels=True, alpha=0.5)\n",
    "\n",
    "# Constrain to specific bounds\n",
    "ax.set_xlim(-30, 40)\n",
    "ax.set_ylim(40, 80)\n",
    "\n",
    "# Set up the fname\n",
    "fname = \"N_europe_regions_corr_delta_P.pdf\"\n",
    "fpath = \"/gws/nopw/j04/canari/users/benhutch/plots\"\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig(os.path.join(fpath,fname),dpi=600)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload dicts\n",
    "importlib.reload(dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a new column in cfs called N_Europe\n",
    "# # which is the average of all of the countries (columns) in dicts.eez_agg_countries\n",
    "# # Convert to three character names first\n",
    "# for key in dicts.iso_mapping:\n",
    "#     merged_df_full = merged_df_full.rename(columns={key: dicts.iso_mapping[key]})\n",
    "\n",
    "# merged_df_full[\"N_Europe\"] = merged_df_full[dicts.eez_agg_countries].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restrict to finite gas demand values\n",
    "# Find the indices where gas_demand_5yrRmean is finite\n",
    "finite_indices = np.isfinite(merged_df['gas_demand_5yrRmean'])\n",
    "\n",
    "# Apply this to the entire dataframe\n",
    "filtered_df = merged_df[finite_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_nao_pr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload functions\n",
    "importlib.reload(funcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the plotting function\n",
    "funcs.plot_time_series(\n",
    "    df=merged_df_nao_pr,\n",
    "    predictor_col_name=\"model_nao_mean\",\n",
    "    predictand_col_name=\"var228 anomaly mean\",\n",
    "    ylabel=\"Normalised anomaly\",\n",
    "    figsize_x=10,\n",
    "    figsize_y=5,\n",
    "    twin_axes=False,\n",
    "    do_detrend_predictor=False,\n",
    "    do_detrend_predictand=False,\n",
    "    normalise_anom=True,\n",
    "    title=\"dcpp-A NAO index (red) and\\n Scandinavia precipitation anomalies (blue)\",\n",
    "    label=\"c\",\n",
    "    fontsize=10,\n",
    "    predictor_color=\"r\",\n",
    "    predictand_color=\"b\",\n",
    "    inverse_predictand=False,\n",
    "    # manual_ylims=[-3.0, 3.0],\n",
    "    calc_rmse=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Create a plot with two y-axes\n",
    "# Time on the x-axes\n",
    "# The variable on the left y-axes is the NAO anomaly (Pa)\n",
    "# The variable on the right y-axes is the wind power (GW) for N_Europe\n",
    "fig, ax1 = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "# Plot the NAO anomaly\n",
    "ax1.plot(filtered_df.index, filtered_df.model_nao_mean / 100, \"b-\")\n",
    "\n",
    "# Set the x-axis label\n",
    "ax1.set_xlabel(\"Time\")\n",
    "\n",
    "# Set the y-axis label\n",
    "ax1.set_ylabel(\"Hindcast NAO anomaly (hPa)\", color=\"b\")\n",
    "\n",
    "# Include a black dashed line for y=0\n",
    "ax1.axhline(0, color=\"black\", linestyle=\"--\")\n",
    "\n",
    "# Set the color of the ticks\n",
    "ax1.tick_params(\"y\", colors=\"b\")\n",
    "\n",
    "# Create a second y-axis\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "# Plot the wind power\n",
    "ax2.plot(merged_df_full.index, merged_df_full.ES, \"r-\")\n",
    "\n",
    "# Set the y-axis label\n",
    "ax2.set_ylabel(\"Spain solar CFs\", color=\"r\")\n",
    "\n",
    "# Set the colour of the ticks\n",
    "ax2.tick_params(\"y\", colors=\"r\")\n",
    "\n",
    "# # Invert the y-axis\n",
    "# ax2.invert_yaxis()\n",
    "\n",
    "# Calculate the correlation between the NAO anomaly and the wind power\n",
    "corr, p = pearsonr(merged_df_full.model_nao_mean, merged_df_full.ES)\n",
    "\n",
    "# Include the correlation and p-value on the plot\n",
    "ax2.text(\n",
    "    0.05,\n",
    "    0.95,\n",
    "    f\"Correlation: {corr:.2f}\\nP-value: {p:.2f}\",\n",
    "    horizontalalignment=\"left\",\n",
    "    verticalalignment=\"top\",\n",
    "    bbox=dict(facecolor=\"white\", alpha=0.5),\n",
    "    transform=ax2.transAxes,\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df_subset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_nao_pr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import linregress\n",
    "\n",
    "# Plot a scatter plot of NAO agaist wind power\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "# Plot the scatter plot\n",
    "plt.scatter(merged_df_nao_pr[\"model_nao_mean\"] / 100, merged_df_nao_pr[\"var228 anomaly mean\"] * 1000, color=\"k\")\n",
    "\n",
    "# Include a line of best fit\n",
    "slope, intercept, r_value, p_value, std_err = linregress(\n",
    "    merged_df_nao_pr[\"model_nao_mean\"] / 100, merged_df_nao_pr[\"var228 anomaly mean\"] * 1000\n",
    ")\n",
    "\n",
    "# Plot the line of best fit\n",
    "plt.plot(\n",
    "    merged_df_nao_pr[\"model_nao_mean\"] / 100,\n",
    "    slope * (merged_df_nao_pr[\"model_nao_mean\"] / 100) + intercept,\n",
    "    color=\"k\",\n",
    ")\n",
    "\n",
    "# Show the values\n",
    "if intercept < 0:\n",
    "    equation = f\"y = {slope:.2f}x - {abs(intercept):.3f}\"\n",
    "else:\n",
    "    equation = f\"y = {slope:.2f}x + {intercept:.3f}\"\n",
    "\n",
    "# plt.text(\n",
    "#     0.05,\n",
    "#     0.95,\n",
    "#     f\"{equation}\\nr={r_value:.2f}, p={p_value:.2f}\",\n",
    "#     horizontalalignment=\"left\",\n",
    "#     verticalalignment=\"top\",\n",
    "#     transform=plt.gca().transAxes,\n",
    "#     bbox=dict(facecolor=\"white\", alpha=0.5),\n",
    "# )\n",
    "\n",
    "# Set the x-axis label\n",
    "plt.xlabel(\"dcpp-A NAO index anomalies (hPa)\", color=\"k\", fontsize=14)\n",
    "\n",
    "# Set the xticks to blue\n",
    "plt.tick_params(axis=\"x\", colors=\"k\")\n",
    "\n",
    "# Set the y-axis label\n",
    "plt.ylabel(\"Observed Scandinavia precip anomalies (mm/day)\", color=\"k\", fontsize=14)\n",
    "\n",
    "# Include a textbox in the bottom right\n",
    "plt.text(\n",
    "    0.95,\n",
    "    0.05,\n",
    "    f\"d\",\n",
    "    fontsize=12,\n",
    "    transform=plt.gca().transAxes,\n",
    "    verticalalignment=\"bottom\",\n",
    "    horizontalalignment=\"right\",\n",
    "    bbox=dict(facecolor=\"white\", alpha=0.5),\n",
    ")\n",
    "\n",
    "# Set the yticks to red\n",
    "plt.tick_params(axis=\"y\", colors=\"k\")\n",
    "\n",
    "# save this as a pdf\n",
    "filename = \"scatter_dcpp-A_NAO_ERA5_scandi_precip_scatter.pdf\"\n",
    "dir = \"/gws/nopw/j04/canari/users/benhutch/plots/\"\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig(f\"{dir}{filename}\",dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a dataframe to store the values\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"slope\": [slope],\n",
    "        \"intercept\": [intercept],\n",
    "        \"r_value\": [r_value],\n",
    "        \"p_value\": [p_value],\n",
    "        \"std_err\": [std_err],\n",
    "    }\n",
    ")\n",
    "\n",
    "# Set up a filename for the dataframe\n",
    "dir = \"/home/users/benhutch/energy-met-corr/coeffs\"\n",
    "\n",
    "# If the directory does not exist, create it\n",
    "if not os.path.exists(dir):\n",
    "    os.makedirs(dir)\n",
    "\n",
    "# Set up the filename\n",
    "fname = \"obs_nao_obs_solar_cfs_slope.csv\"\n",
    "\n",
    "# set up the full path\n",
    "fpath = os.path.join(dir, fname)\n",
    "\n",
    "# Save the datafram\n",
    "df.to_csv(fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the ERA5 data for the NAO index\n",
    "# Use this file\n",
    "# adaptor.mars.internal-1691509121.3261805-29348-4-3a487c76-fc7b-421f-b5be-7436e2eb78d7.nc\n",
    "# in ~/ERA5/\n",
    "# Load the dataset\n",
    "era5_data_path = \"~/ERA5/adaptor.mars.internal-1691509121.3261805-29348-4-3a487c76-fc7b-421f-b5be-7436e2eb78d7.nc\"\n",
    "\n",
    "# Load the data into chunks\n",
    "ds_era5 = xr.open_mfdataset(\n",
    "    era5_data_path,\n",
    "    combine=\"by_coords\",\n",
    "    parallel=True,\n",
    "    chunks={\"time\": 100, \"latitude\": 100, \"longitude\": 100},\n",
    ")[\n",
    "    \"msl\"\n",
    "]  # for mean sea level pressure\n",
    "\n",
    "# Combine the first two expver variables\n",
    "obs_msl = ds_era5.sel(expver=1).combine_first(ds_era5.sel(expver=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constrain obs to ONDJFM\n",
    "obs_msl = obs_msl.sel(time=obs_msl.time.dt.month.isin([10, 11, 12, 1, 2, 3]))\n",
    "\n",
    "# Shift the time index back by 3 months\n",
    "obs_msl_shifted = obs_msl.shift(time=-3)\n",
    "\n",
    "# Take annual means\n",
    "obs_msl_annual = obs_msl_shifted.resample(time=\"Y\").mean()\n",
    "\n",
    "# Throw away years 1959, 2021, 2022 and 2023\n",
    "obs_msl_annual = obs_msl_annual.sel(time=slice(\"1960\", \"2019\"))\n",
    "\n",
    "# Remove the climatology\n",
    "obs_msl_anomaly = obs_msl_annual - obs_msl_annual.mean(dim=\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the lats and lons of the azores\n",
    "lat1, lat2 = dicts.era5_azores[\"lat1\"], dicts.era5_azores[\"lat2\"]\n",
    "lon1, lon2 = dicts.era5_azores[\"lon1\"], dicts.era5_azores[\"lon2\"]\n",
    "\n",
    "# Calculate the mean for the azores gridbox\n",
    "obs_msl_anomaly_azores = obs_msl_anomaly.sel(\n",
    "    latitude=slice(lat1, lat2), longitude=slice(lon1, lon2)\n",
    ").mean(dim=[\"latitude\", \"longitude\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same for iceland\n",
    "lat1, lat2 = dicts.era5_iceland[\"lat1\"], dicts.era5_iceland[\"lat2\"]\n",
    "lon1, lon2 = dicts.era5_iceland[\"lon1\"], dicts.era5_iceland[\"lon2\"]\n",
    "\n",
    "# Calculate the mean for the iceland gridbox\n",
    "obs_msl_anomaly_iceland = obs_msl_anomaly.sel(\n",
    "    latitude=slice(lat1, lat2), longitude=slice(lon1, lon2)\n",
    ").mean(dim=[\"latitude\", \"longitude\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the NAO index (azores - iceland)\n",
    "nao_index = obs_msl_anomaly_azores - obs_msl_anomaly_iceland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXtract the time series\n",
    "nao_index_time = nao_index.time.values\n",
    "\n",
    "# Extract the values\n",
    "nao_index_values = nao_index.values\n",
    "\n",
    "# Create a dataframe\n",
    "nao_df = pd.DataFrame({\"time\": nao_index_time, \"value\": nao_index_values})\n",
    "\n",
    "# Take a centred 8-year running mean\n",
    "nao_running = nao_df.set_index(\"time\").rolling(8, center=True).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have a look at the dataframe\n",
    "nao_running.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the NaN values\n",
    "nao_running = nao_running.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the two dataframes into one, using the index of the first\n",
    "eez_df = eez_cfs.join(nao_running, how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eez_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the value column as 'NAO anomaly (Pa)'\n",
    "eez_df = eez_df.rename(columns={\"value\": \"NAO anomaly (Pa)\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the rows which contain NaN values in the NAO anomaly column\n",
    "eez_df = eez_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eez_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "import pandas as pd\n",
    "\n",
    "# Create a new dataframe with columns for:\n",
    "# 'region' - e.g. Netherlands_7\n",
    "# 'correlation' - the correlation between the NAO and the offshore wind CFs\n",
    "# 'p-value' - the p-value of the correlation\n",
    "# Set up the dataframe\n",
    "correlation_df = pd.DataFrame(columns=[\"region\", \"correlation\", \"p-value\"])\n",
    "\n",
    "# Loop over the regions\n",
    "for region in eez_df.columns[:-1]:\n",
    "    # Calculate the correlation\n",
    "    corr, p = pearsonr(eez_df[region], eez_df[\"NAO anomaly (Pa)\"])\n",
    "\n",
    "    # Create a new DataFrame to append\n",
    "    df_to_append = pd.DataFrame(\n",
    "        {\"region\": [region], \"correlation\": [corr], \"p-value\": [p]}\n",
    "    )\n",
    "\n",
    "    # Append to the dataframe\n",
    "    correlation_df = pd.concat([correlation_df, df_to_append], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the numbers from the region column by removing the last 2 characters\n",
    "correlation_df[\"region\"] = correlation_df[\"region\"].str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if any of the region names contain the string \"_\" then remove it\n",
    "correlation_df[\"region\"] = correlation_df[\"region\"].str.replace(\"_\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EEZ_shapefile[\"SOVEREIGN1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two new columns in the geopandas dataframe 'EEZ_shapefile'\n",
    "# 'correlation' - the correlation between the NAO and the offshore wind CFs\n",
    "# 'p-value' - the p-value of the correlation\n",
    "EEZ_shapefile[\"correlation\"] = np.nan\n",
    "EEZ_shapefile[\"p-value\"] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EEZ_shapefile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over the regions in correlation_df\n",
    "for region in correlation_df[\"region\"]:\n",
    "    # Extract the row from correlation_df\n",
    "    row = correlation_df[correlation_df[\"region\"] == region]\n",
    "\n",
    "    # Extract the correlation and p-value\n",
    "    corr = row[\"correlation\"].values[0]\n",
    "    p = row[\"p-value\"].values[0]\n",
    "\n",
    "    # Set the values in the EEZ_shapefile\n",
    "    EEZ_shapefile.loc[EEZ_shapefile[\"TERRITORY1\"] == region, \"correlation\"] = corr\n",
    "    EEZ_shapefile.loc[EEZ_shapefile[\"TERRITORY1\"] == region, \"p-value\"] = p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EEZ_shapefile[\"TERRITORY1\"] == \"France\", \"correlation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the list of Terrirories\n",
    "territories = EEZ_shapefile[\"TERRITORY1\"]\n",
    "\n",
    "# Convert to a list\n",
    "territories = list(territories)\n",
    "\n",
    "# Print the territories\n",
    "print(territories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constrain EEZ shapefile to only include the territories in the list\n",
    "EEZ_shapefile = EEZ_shapefile[EEZ_shapefile[\"TERRITORY1\"].isin(dicts.countries_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the correlation values for FRance\n",
    "print(EEZ_shapefile[EEZ_shapefile[\"SOVEREIGN1\"] == \"France\"][\"correlation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "# Now plot the EEZ_shapefile with the correlation as the color\n",
    "plt.figure(figsize=(10, 10))\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "EEZ_shapefile.plot(\n",
    "    column=\"correlation\", ax=ax, legend=True, cmap=\"coolwarm\", shrink=0.5\n",
    ")\n",
    "# Use cartopy to add the coastlines\n",
    "ax.coastlines()\n",
    "# Make the colorbar smaller\n",
    "cbar = ax.get_figure().get_axes()[1]\n",
    "cbar.set_ylabel(\"Correlation\", fontsize=12)\n",
    "cbar.tick_params(labelsize=10)\n",
    "\n",
    "# Constrain to specific bounds\n",
    "ax.set_xlim(-50, 50)\n",
    "ax.set_ylim(30, 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now plot the EEZ_shapefile with the correlation as the color\n",
    "fig, ax = plt.subplots(figsize=(10, 10), subplot_kw={\"projection\": ccrs.PlateCarree()})\n",
    "cax = EEZ_shapefile.plot(\n",
    "    column=\"correlation\", ax=ax, cmap=\"coolwarm\", add_colorbar=False\n",
    ")\n",
    "\n",
    "# Use cartopy to add the coastlines\n",
    "ax.coastlines()\n",
    "\n",
    "# Add colorbar\n",
    "cbar = fig.colorbar(cax.collections[0], ax=ax, shrink=0.5)\n",
    "cbar.set_label(\"Correlation\")\n",
    "\n",
    "# Constrain to specific bounds\n",
    "ax.set_xlim(-50, 50)\n",
    "ax.set_ylim(30, 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
